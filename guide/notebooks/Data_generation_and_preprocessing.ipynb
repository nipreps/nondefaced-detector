{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Details\n",
    "\n",
    "TBA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "# Define paths\n",
    "ROOT_DIR = '/tf/shank/HDDLinux/Stanford/data/mriqc-shared/conformed'\n",
    "\n",
    "face_path = os.path.join(ROOT_DIR, 'face/128')\n",
    "defaced_path = os.path.join(ROOT_DIR, 'face_defaced/128')\n",
    "refaced_path = os.path.join(ROOT_DIR, 'face_refaced/128')\n",
    "\n",
    "paths_d = []\n",
    "paths_f = []\n",
    "paths_r = []\n",
    "\n",
    "for path in glob(defaced_path + \"/*/*.nii*\"):\n",
    "    DS = path.split('/')[-2]\n",
    "    paths_d.append(path)\n",
    "    \n",
    "for path in glob(refaced_path + \"/*/*.nii*\"):\n",
    "    DS = path.split('/')[-2]\n",
    "    paths_r.append(path)\n",
    "    \n",
    "for path in glob(face_path + \"/*/*.nii*\"):\n",
    "    DS = path.split('/')[-2]\n",
    "    paths_f.append(path)\n",
    "    \n",
    "\n",
    "def generate_datasets(fpaths, dpaths, size, typ ='faced'):\n",
    "    \n",
    "    if typ not in ['faced', 'refaced']:\n",
    "        print(\"Incorrect value for t. Choose from [faced, refaced]\")\n",
    "        return\n",
    "    \n",
    "    random.shuffle(fpaths)\n",
    "    test_f = fpaths[:size]\n",
    "    main_f = fpaths[size:]\n",
    "\n",
    "    test_d = []\n",
    "    for t in test_f:\n",
    "        if typ == 'faced':\n",
    "            test_d.append(t.replace('face', 'face_defaced'))\n",
    "        \n",
    "        if typ == 'refaced':\n",
    "            DS = t.split('/')[-2]\n",
    "            sub = t.split('/')[-1].replace('_defaced_refaced', '').split('.nii.gz')[0]\n",
    "            search_pattern = os.path.join(DS, sub)\n",
    "            \n",
    "            # match pattern from defaced dataset\n",
    "            for _d in dpaths:\n",
    "                if search_pattern in _d:\n",
    "                    test_d.append(_d)\n",
    "                \n",
    "\n",
    "    test = test_f + test_d\n",
    "    labels_test = [1]*len(test_f) + [0]*len(test_d)\n",
    "    \n",
    "    # remove T_A_D from defaced volume set\n",
    "    main_d = list(set(dpaths) - set(test_d))\n",
    "    \n",
    "    labels_main = [1]*len(main_f) + [0]*len(main_d)\n",
    "    main = main_f + main_d\n",
    "    \n",
    "    return main, labels_main, test, labels_test\n",
    "\n",
    "A_2, L_A_2, T_A, L_T_A = generate_datasets(paths_f, paths_d, 49, typ='faced')\n",
    "B_2, L_B_2, T_B, L_T_B = generate_datasets(paths_r, paths_d, 49, typ='refaced')\n",
    "\n",
    "print(len(A_2), len(T_A))\n",
    "print(len(B_2), len(T_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/shank/Stanford/mri-face-detector/guide/notebooks/tmpf6dd5442.nii.gz /tf/shank/Stanford/mri-face-detector/guide/notebooks/tmpcit76xfz.nii.gz\n"
     ]
    }
   ],
   "source": [
    "from nondefaced_detector import preprocess\n",
    "vol_path = '../../examples/sample_vols/IXI002-Guys-0828-T1.nii.gz'\n",
    "save_path = ''\n",
    "ppath, cpath = preprocess.preprocess(vol_path, save_path=save_path)\n",
    "print(ppath, cpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate n-fold CV Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import shuffle\n",
    "import os\n",
    "\n",
    "def generate_CSV(paths, labels, save_path, test_paths=None, test_labels=None, n=15, mode='CV'):\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df[\"X\"] = paths\n",
    "    df[\"Y\"] = labels\n",
    "    df.to_csv(os.path.join(save_path, \"all.csv\"))\n",
    "    \n",
    "    if mode == 'CV':\n",
    "        SPLITS = n\n",
    "        skf = StratifiedKFold(n_splits=SPLITS)\n",
    "        fold_no = 1\n",
    "\n",
    "        for train_index, test_index in skf.split(paths, labels):\n",
    "            out_path = os.path.join(save_path, \"train_test_fold_{}/csv/\".format(fold_no))\n",
    "\n",
    "            if not os.path.exists(out_path):\n",
    "                os.makedirs(out_path)\n",
    "\n",
    "            image_train, image_test = (\n",
    "                itemgetter(*train_index)(paths),\n",
    "                itemgetter(*test_index)(paths),\n",
    "            )\n",
    "\n",
    "            label_train, label_test = (\n",
    "                itemgetter(*train_index)(labels),\n",
    "                itemgetter(*test_index)(labels),\n",
    "            )\n",
    "\n",
    "            train_data = {\"X\": image_train , \"Y\": label_train}\n",
    "            df_train = pd.DataFrame(train_data)\n",
    "            df_train.to_csv(os.path.join(out_path, \"training.csv\"), index=False)\n",
    "\n",
    "            validation_data = {\"X\": image_test, \"Y\": label_test}\n",
    "            df_validation = pd.DataFrame(validation_data)\n",
    "            df_validation.to_csv(os.path.join(out_path, \"validation.csv\"), index=False)\n",
    "\n",
    "            fold_no += 1\n",
    "    else:\n",
    "        train_data = {\"X\": paths , \"Y\": labels}\n",
    "        df_train = pd.DataFrame(train_data)\n",
    "        df_train.to_csv(os.path.join(save_path, \"training.csv\"), index=False)\n",
    "        \n",
    "        test_data = {\"X\": test_paths , \"Y\": test_labels}\n",
    "        df_test = pd.DataFrame(test_data)\n",
    "        df_test.to_csv(os.path.join(save_path, \"testing.csv\"), index=False)\n",
    "        \n",
    "ROOTDIR = '/tf/shank/HDDLinux/Stanford/data/mriqc-shared/experiments'\n",
    "\n",
    "## CROSS VALIDATION\n",
    "# generate_CSV(A_2, L_A_2, \"experiments/experiment_A/csv_F15\")\n",
    "generate_CSV(B_2, L_B_2, os.path.join(ROOTDIR, \"experiment_B/128/csv_F15\"), mode='CV')\n",
    "\n",
    "\n",
    "## DEFINE A ROOT DIR where all the data will be stored <<<<<\n",
    "# ROOTDIR = '/work/06850/sbansal6/maverick2/mriqc-shared/experiments' \n",
    "\n",
    "## FULL DATASET\n",
    "# generate_CSV(A_2,\n",
    "#              L_A_2,\n",
    "#              os.path.join(ROOTDIR, 'experiment_A/128/csv_full'),\n",
    "#              test_paths=T_A,\n",
    "#              test_labels=L_T_A,\n",
    "#              mode='full')\n",
    "\n",
    "# generate_CSV(B_2,\n",
    "#              L_B_2,\n",
    "#              os.path.join(ROOTDIR, 'experiment_B/128/csv_full'),\n",
    "#              test_paths=T_B,\n",
    "#              test_labels=L_T_B,\n",
    "#              mode='full')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate tfrecords for n-fold CV datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nobrainer\n",
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from shutil import *\n",
    "import subprocess\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_tfrecords(csv_path, records_save_path, mode='CV'):\n",
    "    \n",
    "    os.makedirs(records_save_path, exist_ok=True)\n",
    "    train_csv_path = os.path.join(csv_path, \"training.csv\")\n",
    "    train_paths = pd.read_csv(train_csv_path)[\"X\"].values\n",
    "    train_labels = pd.read_csv(train_csv_path)[\"Y\"].values\n",
    "    train_D = list(zip(train_paths, train_labels))\n",
    "    \n",
    "    random.shuffle(train_D)\n",
    "    train_write_path = os.path.join(records_save_path, 'data-train_shard-{shard:03d}.tfrec')\n",
    "    \n",
    "    nobrainer.tfrecord.write(\n",
    "        features_labels=train_D,\n",
    "        filename_template=train_write_path,\n",
    "        examples_per_shard=3)\n",
    "    \n",
    "    if mode =='CV':\n",
    "        vt_csv_path = os.path.join(csv_path, \"validation.csv\")\n",
    "        namefill = 'valid'\n",
    "    else:\n",
    "        vt_csv_path = os.path.join(csv_path, \"testing.csv\")\n",
    "        namefill = 'test'\n",
    "        \n",
    "    vt_paths = pd.read_csv(vt_csv_path)[\"X\"].values\n",
    "    vt_labels = pd.read_csv(vt_csv_path)[\"Y\"].values\n",
    "    vt_D = list(zip(vt_paths, vt_labels))\n",
    "    random.shuffle(vt_D)\n",
    "    vt_write_path = os.path.join(records_save_path, 'data-{}_shard-{shard:03d}.tfrec'.format(namefill))\n",
    "\n",
    "    nobrainer.tfrecord.write(\n",
    "        features_labels=vt_D,\n",
    "        filename_template=vt_write_path,\n",
    "        examples_per_shard=1)\n",
    "        \n",
    "\n",
    "ROOTDIR = '/tf/shank/HDDLinux/Stanford/data/mriqc-shared/experiments'\n",
    "\n",
    "# Cross-Validation \n",
    "# SPLITS = 15\n",
    "# for fold in range(1, SPLITS+1):\n",
    "#     print(\"FOLD: \", fold)\n",
    "#     csv_path = os.path.join(\n",
    "#         ROOTDIR, \"experiment_B/128/csv_F15/train_test_fold_{}/csv/\".format(fold)\n",
    "#     )\n",
    "    \n",
    "#     tf_records_dir = os.path.join(\n",
    "#         ROOTDIR, \"experiment_B/128/tfrecords_F15/tfrecords_fold_{}/\".format(fold)\n",
    "#     )\n",
    "#     generate_tfrecords(csv_path, tf_records_dir)\n",
    "\n",
    "\n",
    "# Test (full dataset)\n",
    "# experiment_A\n",
    "# csv_path = os.path.join(ROOT_DIR, \"experiment_A/128/csv_full\")\n",
    "# tf_records_dir = os.path.join(ROOT_DIR, \"experiment_A/128/tfrecords_full\")\n",
    "# generate_tfrecords(csv_path, tf_records_dir, mode='test')\n",
    "\n",
    "# experiment_B\n",
    "# csv_path = os.path.join(ROOT_DIR, \"experiment_B/128/csv_full\")\n",
    "# tf_records_dir = os.path.join(ROOT_DIR, \"experiment_B/128/tfrecords_full\")\n",
    "# generate_tfrecords(csv_path, tf_records_dir, mode='test')\n",
    "\n",
    "## Main held-out Test Dataset\n",
    "csv_path = '/tf/shank/HDDLinux/Stanford/data/mriqc-shared/test_ixi/csv/testing.csv'\n",
    "records_save_path = '/tf/shank/HDDLinux/Stanford/data/mriqc-shared/test_ixi/tfrecords_new'\n",
    "paths = pd.read_csv(csv_path)[\"X\"].values\n",
    "labels = pd.read_csv(csv_path)[\"Y\"].values\n",
    "\n",
    "vt_D = list(zip(paths, labels))\n",
    "random.shuffle(vt_D)\n",
    "\n",
    "write_path = os.path.join(records_save_path, 'data-test_shard-{shard:03d}.tfrec')\n",
    "\n",
    "nobrainer.tfrecord.write(\n",
    "    features_labels=vt_D,\n",
    "    filename_template=write_path,\n",
    "    examples_per_shard=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
