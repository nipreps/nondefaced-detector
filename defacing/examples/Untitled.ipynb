{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.path)\n",
    "print(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-05 15:55:20.368160: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/cuda10_0/nccl/2.4.7/lib:/opt/apps/cuda10_0/cudnn/7.6.2/lib64:/opt/apps/cuda/10.0/lib64:/opt/apps/intel17/python3/3.6.3/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib:/opt/intel/debugger_2017/libipt/intel64/lib:/opt/intel/debugger_2017/iga/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/intel/compilers_and_libraries_2017.4.196/linux/daal/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/ipp/lib/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64:/opt/apps/gcc/5.4.0/lib64:/opt/apps/gcc/5.4.0/lib:/opt/apps/cuda/10.1/targets/x86_64-linux/lib:/work/06850/sbansal6/maverick2:/opt/apps/cuda/10.1/targets/x86_64-linux/lib:/work/06850/sbansal6/maverick2\n",
      "2020-04-05 15:55:20.368319: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/cuda10_0/nccl/2.4.7/lib:/opt/apps/cuda10_0/cudnn/7.6.2/lib64:/opt/apps/cuda/10.0/lib64:/opt/apps/intel17/python3/3.6.3/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib:/opt/intel/debugger_2017/libipt/intel64/lib:/opt/intel/debugger_2017/iga/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/opt/intel/compilers_and_libraries_2017.4.196/linux/daal/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.7:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/ipp/lib/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64:/opt/apps/gcc/5.4.0/lib64:/opt/apps/gcc/5.4.0/lib:/opt/apps/cuda/10.1/targets/x86_64-linux/lib:/work/06850/sbansal6/maverick2:/opt/apps/cuda/10.1/targets/x86_64-linux/lib:/work/06850/sbansal6/maverick2\n",
      "2020-04-05 15:55:20.368341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-04-05 15:55:25.592744: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-04-05 15:55:25.604759: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100075000 Hz\n",
      "2020-04-05 15:55:25.605647: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5595be2c5850 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-05 15:55:25.605693: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-05 15:55:25.609263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-04-05 15:55:26.209833: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5595be386c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-05 15:55:26.209889: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-04-05 15:55:26.209903: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-04-05 15:55:26.209921: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-04-05 15:55:26.209933: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2020-04-05 15:55:26.213499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.214620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.215665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 2 with properties: \n",
      "pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.216703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 3 with properties: \n",
      "pciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.217162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-04-05 15:55:26.218888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-04-05 15:55:26.220554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-04-05 15:55:26.220902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-04-05 15:55:26.223212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-04-05 15:55:26.224907: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-04-05 15:55:26.229368: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-05 15:55:26.237346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2020-04-05 15:55:26.237395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-04-05 15:55:26.241986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-05 15:55:26.242011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 2 3 \n",
      "2020-04-05 15:55:26.242025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y N N \n",
      "2020-04-05 15:55:26.242036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N N N \n",
      "2020-04-05 15:55:26.242096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 2:   N N N Y \n",
      "2020-04-05 15:55:26.242135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 3:   N N Y N \n",
      "2020-04-05 15:55:26.248974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
      "2020-04-05 15:55:26.250562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:1 with 10481 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "2020-04-05 15:55:26.252105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:2 with 10481 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "2020-04-05 15:55:26.253633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:3 with 10481 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)\n",
      "Available GPUs:  ['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3']\n",
      "WARNING:tensorflow:From train.py:81: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "2020-04-05 15:55:26.273365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.274449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.275514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 2 with properties: \n",
      "pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.276565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 3 with properties: \n",
      "pciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.276637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-04-05 15:55:26.276664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-04-05 15:55:26.276688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-04-05 15:55:26.276733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-04-05 15:55:26.276758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-04-05 15:55:26.276782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-04-05 15:55:26.276806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-05 15:55:26.284967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2020-04-05 15:55:26.285100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-05 15:55:26.285115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 2 3 \n",
      "2020-04-05 15:55:26.285125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y N N \n",
      "2020-04-05 15:55:26.285134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N N N \n",
      "2020-04-05 15:55:26.285143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 2:   N N N Y \n",
      "2020-04-05 15:55:26.285152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 3:   N N Y N \n",
      "2020-04-05 15:55:26.291918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
      "2020-04-05 15:55:26.292914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:1 with 10481 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "2020-04-05 15:55:26.293930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:2 with 10481 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "2020-04-05 15:55:26.295037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:3 with 10481 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)\n",
      "============== paths: 1068, labels: 1068 ================\n",
      "============== paths: 152, labels: 152 ================\n",
      "No. of training and validation batches are: 534 19\n",
      "2020-04-05 15:55:26.325503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.326509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.327572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 2 with properties: \n",
      "pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.328584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 3 with properties: \n",
      "pciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.328629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-04-05 15:55:26.328656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-04-05 15:55:26.328679: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-04-05 15:55:26.328707: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-04-05 15:55:26.328731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-04-05 15:55:26.328754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-04-05 15:55:26.328777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-05 15:55:26.336779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2020-04-05 15:55:26.338133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.339172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.340238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 2 with properties: \n",
      "pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.341316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 3 with properties: \n",
      "pciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2020-04-05 15:55:26.341359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-04-05 15:55:26.341391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-04-05 15:55:26.341415: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-04-05 15:55:26.341438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-04-05 15:55:26.341460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-04-05 15:55:26.341483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-04-05 15:55:26.341506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-05 15:55:26.349918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2020-04-05 15:55:26.350049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-05 15:55:26.350066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 2 3 \n",
      "2020-04-05 15:55:26.350080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y N N \n",
      "2020-04-05 15:55:26.350091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N N N \n",
      "2020-04-05 15:55:26.350102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 2:   N N N Y \n",
      "2020-04-05 15:55:26.350113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 3:   N N Y N \n",
      "2020-04-05 15:55:26.357845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
      "2020-04-05 15:55:26.359037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10481 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\n",
      "2020-04-05 15:55:26.360262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10481 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\n",
      "2020-04-05 15:55:26.361459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10481 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Training from scratch**********\n",
      "Training using single GPU or CPU..\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "axial (InputLayer)           [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 8)         80        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 8)         584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output_node (Dense)          (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 150,073\n",
      "Trainable params: 149,849\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 534 steps, validate for 19 steps\n",
      "Epoch 1/25\n",
      "2020-04-05 15:55:39.284772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-04-05 15:56:22.629789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-05 15:56:23.844981: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Not found: ./bin/ptxas not found\n",
      "Relying on driver to perform ptx compilation. This message will be only logged once.\n",
      "2020-04-05 15:56:25.991883: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "2020-04-05 15:56:25.991965: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 4 GPUs\n",
      "2020-04-05 15:56:25.994947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1\n",
      "  1/534 [..............................] - ETA: 7:15:18 - loss: 1.5609 - accuracy: 0.5000 - sensitivity: 1.0000 - specificity: 0.0000e+002020-04-05 15:56:27.289910: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1378] CUPTI activity buffer flushed\n",
      "2020-04-05 15:56:27.289960: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 388 callback api events and 388 activity events.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.649936). Check your callbacks.\n",
      " 12/534 [..............................] - ETA: 35:45 - loss: 1.0744 - accuracy: 0.5208 - sensitivity: 0.7083 - specificity: 0.3333    ^C\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore train.py -jn split-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs:  ['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--GPU GPU] -jn JOB_NAME\n",
      "ipykernel_launcher.py: error: the following arguments are required: -jn/--job_name\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/apps/intel17/python3/3.6.3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "import timeit\n",
    "import argparse\n",
    "import getpass\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../defacing\")\n",
    "from training.training import trainer\n",
    "from helpers.utils import get_available_gpus\n",
    "from distutils.dir_util import copy_tree\n",
    "import tensorflow as tf\n",
    "\n",
    "list_gpu = get_available_gpus()\n",
    "n_gpu = len(list_gpu)\n",
    "print(\"Available GPUs: \", list_gpu)\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Training DefacingNet\")\n",
    "parser.add_argument(\"--GPU\", default=\"0\", type=str, help=\"which GPU to use\")\n",
    "parser.add_argument(\n",
    "    \"-jn\",\n",
    "    \"--job_name\",\n",
    "    required=True,\n",
    "    type=str,\n",
    "    help=\"The job name is required. All the training will be saved here.\",\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "t0 = timeit.default_timer()\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.GPU\n",
    "print(\n",
    "    \"GPU Availability: \",\n",
    "    tf.test.is_gpu_available(cuda_only=True, min_cuda_compute_capability=None),\n",
    ")\n",
    "\n",
    "\n",
    "Kfolds = 10\n",
    "nfolds = list(range(1, Kfolds + 1))\n",
    "\n",
    "for fold in nfolds:\n",
    "    root_dir = \"./Logs/\" + args.job_name + \"/train_test_fold_{}\".format(fold)\n",
    "    dir_path = \"./Logs/\" + args.job_name + \"/train_test_fold_{}/csv/\".format(fold)\n",
    "\n",
    "    # currently a very hacky way of doing this -- will need to fix later\n",
    "    from_dir = os.path.abspath(\n",
    "        \"./csv/faced_defaced/train_test_fold_{}/csv/\".format(fold)\n",
    "    )\n",
    "    to_dir = dir_path\n",
    "    copy_tree(from_dir, to_dir)\n",
    "\n",
    "    train_csv_path = os.path.join(dir_path, \"training.csv\")\n",
    "    valid_csv_path = os.path.join(dir_path, \"validation.csv\")\n",
    "\n",
    "    # Model Path\n",
    "    model_path = root_dir + \"/\" + args.job_name\n",
    "\n",
    "    # create a path to where the model will be saved\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.makedirs(root_dir)\n",
    "\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # basic job info text file to identify jobs\n",
    "    basic_job_info = os.path.join(os.path.abspath(root_dir), \"job_info.txt\")\n",
    "    with open(basic_job_info, \"w\") as f:\n",
    "        f.write(\"Jobname: %s\\n\" % args.job_name)\n",
    "        f.write(\"Created on: %s\\n\" % str(datetime.datetime.now()))\n",
    "        f.write(\"Created by: %s\\n\" % str(getpass.getuser()))\n",
    "        f.write(\"Model store path: %s\\n\" % os.path.abspath(model_path))\n",
    "        f.write(\n",
    "            \"GPU Availability: %s\\n\"\n",
    "            % str(\n",
    "                tf.test.is_gpu_available(\n",
    "                    cuda_only=True, min_cuda_compute_capability=None\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        f.write(\"Available GPUs: %s\\n\" % (\",\".join(list_gpu)))\n",
    "\n",
    "    train = trainer(\n",
    "        train_csv_path,\n",
    "        valid_csv_path,\n",
    "        basic_job_info,\n",
    "        model_path,\n",
    "        image_size=32,\n",
    "        batch_size=8,\n",
    "        initial_epoch=0,\n",
    "        nepochs=25,\n",
    "        dropout=0.4,\n",
    "        nclasses=2,\n",
    "        nchannels=1,\n",
    "        gpus=4,\n",
    "    )\n",
    "    train.train()\n",
    "\n",
    "    elapsed = timeit.default_timer() - t0\n",
    "    print(\"Time: {:.3f} min\".format(elapsed / 60))\n",
    "    del train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/06850/sbansal6/maverick2/mri-face-detector/defacing/examples/csv/faced_defaced/train_test_fold_1/csv /work/06850/sbansal6/maverick2/mri-face-detector/defacing/examples/csv/faced_defaced/train_test_fold_1/csv/training.csv\n",
      "============== paths: 1068, labels: 1068 ================\n",
      "============== Samples/Epoch: 4272 ================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c2b120b3ce79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0mtraining_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGeneratoronFly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_csv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_transform_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m133\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m133\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m# print (training_generator.__len__())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import os, sys\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import imgaug\n",
    "from imgaug import augmenters as iaa\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "sys.path.append('..')\n",
    "from helpers.utils import *\n",
    "from skimage.restoration import denoise_wavelet\n",
    "\n",
    "\n",
    "class DataGeneratoronFly(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "\t\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_csv,\n",
    "        nclasses=2,\n",
    "        image_size=128,\n",
    "        batch_size=32,\n",
    "        nchannels=1,\n",
    "        mode=\"Train\",\n",
    "        name=None,\n",
    "        samples_per_epoch=None,\n",
    "        transform=None,\n",
    "    ):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.nchannels = nchannels\n",
    "        self.nclasses = nclasses\n",
    "        self.transform = transform\n",
    "        self.name = name\n",
    "        self.paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        labels = pd.read_csv(data_csv)[\"Y\"].values\n",
    "        paths = pd.read_csv(data_csv)[\"X\"].values\n",
    "\n",
    "        index = np.arange(len(paths))\n",
    "        np.random.shuffle(index)\n",
    "\n",
    "        labels = labels[index]\n",
    "        paths = paths[index]\n",
    "        \n",
    "        if mode.lower() in [\"train\", \"valid\", \"test\"]:\n",
    "            self.mode = mode.lower()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"mode should be one among ['Train', 'Valid', 'Test'], given argument: {}\".format(\n",
    "                    mode\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        if mode == \"Train\":\n",
    "            minarr = [np.sum(labels == i) for i in range(nclasses)]\n",
    "            mincount = np.min(minarr)\n",
    "            for i in range(nclasses):\n",
    "                self.paths.extend(paths[labels == i][:mincount])\n",
    "                self.labels.extend(labels[labels == i][:mincount])\n",
    "\n",
    "            self.paths = np.array(self.paths)\n",
    "            self.labels = np.array(self.labels)\n",
    "\n",
    "        elif mode == \"Valid\":\n",
    "            self.paths = np.array(paths)\n",
    "            self.labels = np.array(labels)\n",
    "\n",
    "        assert len(np.unique(self.labels)) == nclasses\n",
    "        self.len_arr = [sum(self.labels == arr) for arr in np.unique(self.labels)]\n",
    "\n",
    "        index = np.arange(len(self.paths))\n",
    "        np.random.shuffle(index)\n",
    "\n",
    "        self.paths = self.paths[index]\n",
    "        self.labels = self.labels[index]\n",
    "        \n",
    "        print(\n",
    "            \"============== paths: {}, labels: {} ================\".format(\n",
    "                len(self.paths), len(self.labels)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if samples_per_epoch is None:\n",
    "            if mode == \"Train\":\n",
    "                self.samples_per_epoch = 4 * len(self.paths)\n",
    "            else:\n",
    "                self.samples_per_epoch = len(self.paths)\n",
    "        else:\n",
    "            self.samples_per_epoch = samples_per_epoch\n",
    "            \n",
    "        print(\n",
    "            \"============== Samples/Epoch: {} ================\".format(\n",
    "                self.samples_per_epoch\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "            Denotes the number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(self.samples_per_epoch / self.batch_size))\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "        \n",
    "# #         print(\"getitem index: \", index)\n",
    "#         # Generate indexes of the batch\n",
    "#         X1, X2, X3, y = self.__data_generation(index)\n",
    "#         if self.name == \"combined\":\n",
    "#             return [X1, X2, X3], y\n",
    "#         elif self.name == \"axial\":\n",
    "# #             tf_dataset = tf.data.Dataset.from_tensor_slices((X1, y))\n",
    "#             return X1, y\n",
    "#         elif self.name == \"coronal\":\n",
    "#             return X2, y\n",
    "#         elif self.name == \"sagittal\":\n",
    "#             return X3, y\n",
    "\n",
    "    def _standardize_volume(self, volume, mask=None):\n",
    "        \"\"\"\n",
    "\t\t\tvolume: volume which needs to be normalized\n",
    "\t\t\tmask: brain mask, only required if you prefer not to\n",
    "\t\t\t\tconsider the effect of air in normalization\n",
    "\t\t\"\"\"\n",
    "        if mask != None:\n",
    "            volume = volume * mask\n",
    "\n",
    "        mean = np.mean(volume[volume != 0])\n",
    "        std = np.std(volume[volume != 0])\n",
    "\n",
    "        return (volume - mean) / std\n",
    "\n",
    "    def _normalize_volume(self, volume, mask=None, _type=\"MinMax\"):\n",
    "        \"\"\"\n",
    "\t\t\tvolume: volume which needs to be normalized\n",
    "\t\t\tmask: brain mask, only required if you prefer not to\n",
    "\t\t\t\tconsider the effect of air in normalization\n",
    "\t\t\t_type: {'Max', 'MinMax', 'Sum'}\n",
    "\t\t\"\"\"\n",
    "        if mask != None:\n",
    "            volume = mask * volume\n",
    "\n",
    "        min_vol = np.min(volume)\n",
    "        max_vol = np.max(volume)\n",
    "        sum_vol = np.sum(volume)\n",
    "\n",
    "        if _type == \"MinMax\":\n",
    "            return (volume - min_vol) / (max_vol - min_vol)\n",
    "        elif _type == \"Max\":\n",
    "            return volume / max_vol\n",
    "        elif _type == \"Sum\":\n",
    "            return volume / sum_vol\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid _type, allowed values are: {}\".format(\"Max, MinMax, Sum\")\n",
    "            )\n",
    "\n",
    "    def _augmentation(self, volume):\n",
    "        \"\"\"\n",
    "\t\t\tAugmenters that are safe to apply to masks\n",
    "\t\t\tSome, such as Affine, have settings that make them unsafe, so always\n",
    "\t\t\ttest your augmentation on masks\n",
    "\t\t\"\"\"\n",
    "        volume_shape = volume.shape\n",
    "        det = self.transform.to_deterministic()\n",
    "        volume = det.augment_image(volume)\n",
    "\n",
    "        assert volume.shape == volume_shape, \"Augmentation shouldn't change volume size\"\n",
    "        return volume\n",
    "\n",
    "    def _resizeVolume(self, volume):\n",
    "        \"\"\"\n",
    "\t\t\tresizes the original volume such that every patch is\n",
    "\t\t\t75% of original volume\n",
    "\n",
    "\t\t\tvolume: numpy 3d tensor\n",
    "\t\t\"\"\"\n",
    "        ratio = 1.0\n",
    "\n",
    "        orig_size = (\n",
    "            int(self.image_size / ratio),\n",
    "            int(self.image_size / ratio),\n",
    "            int(self.image_size / ratio),\n",
    "        )\n",
    "        resized_volume = resize_sitk(volume, orig_size)\n",
    "        return resized_volume\n",
    "\n",
    "    def _get_random_slices(self, volume):\n",
    "        \"\"\"\n",
    "\t\t\"\"\"\n",
    "        dimensions = volume.shape\n",
    "        img = np.zeros((dimensions[0], dimensions[1], 3))\n",
    "        x = np.random.randint(dimensions[0] // 4, 3 * dimensions[0] // 4)\n",
    "        z = np.random.randint(dimensions[1] // 4, 3 * dimensions[1] // 4)\n",
    "        y = np.random.randint(dimensions[2] // 4, 3 * dimensions[2] // 4)\n",
    "        slice_x = volume[x, :, :]\n",
    "        slice_y = volume[:, y, :]\n",
    "        slice_z = volume[:, :, z]\n",
    "\n",
    "        return slice_x[..., None], slice_y[..., None], slice_z[..., None]\n",
    "\n",
    "    def _center_align(self, volume):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return volume\n",
    "\n",
    "    def _axis_align(self, volume):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return volume\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        \"\"\"\n",
    "        balanced data loader\n",
    "        \"\"\"\n",
    "        X1, X2, X3 = [], [], []\n",
    "        Y = []\n",
    "        nclass_batch = self.batch_size // self.nclasses\n",
    "        \n",
    "#         print(\"Nclass batch: \", nclass_batch)\n",
    "        \n",
    "        for i in range(nclass_batch):\n",
    "            for ii in np.unique(self.labels):\n",
    "                # try:\n",
    "                pid_path = self.paths[self.labels == ii][\n",
    "                    int(index * nclass_batch + i) % self.len_arr[ii]\n",
    "                ]\n",
    "                label = ii  # np.eye(self.nclasses)[ii]\n",
    "\n",
    "                volume, affine, size = load_vol(pid_path)\n",
    "                volume = self._axis_align(volume)\n",
    "                volume = self._center_align(volume)\n",
    "                volume = self._resizeVolume(volume)\n",
    "                volume = self._standardize_volume(volume)\n",
    "                volume = self._normalize_volume(volume)\n",
    "\n",
    "                if (self.mode.lower() == \"train\") and self.transform:\n",
    "                    volume = self._augmentation(volume)\n",
    "\n",
    "                ax, sg, co = self._get_random_slices(volume)\n",
    "\n",
    "                if ax.shape == sg.shape == co.shape:\n",
    "                    X1.append(ax)\n",
    "                    X2.append(sg)\n",
    "                    X3.append(co)\n",
    "                    Y.append(label)\n",
    "                # except:\n",
    "                # \tcontinue\n",
    "\n",
    "        X1, X2, X3, Y = np.array(X1), np.array(X2), np.array(X3), np.array(Y)\n",
    "        \n",
    "        \n",
    "        index = np.arange(len(X1))\n",
    "        np.random.shuffle(index)\n",
    "        \n",
    "        X1, X2, X3, Y = X1[index], X2[index], X3[index], Y[index]\n",
    "        \n",
    "#         print(\"X1.shape: \", X1.shape)\n",
    "#         print(Y)\n",
    "        \n",
    "        return X1, X2, X3, Y\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dir_path = os.path.abspath(\"csv/faced_defaced/train_test_fold_1/csv/\")\n",
    "\n",
    "    csv_path = os.path.join(dir_path, \"training.csv\")\n",
    "    \n",
    "    print(dir_path, csv_path)\n",
    "    \n",
    "    augmentation = iaa.SomeOf(\n",
    "        (0, 3),\n",
    "        [\n",
    "            iaa.Fliplr(0.5),\n",
    "            iaa.Flipud(0.5),\n",
    "            iaa.Noop(),\n",
    "            iaa.OneOf(\n",
    "                [iaa.Affine(rotate=90), iaa.Affine(rotate=180), iaa.Affine(rotate=270)]\n",
    "            ),\n",
    "            # iaa.GaussianBlur(sigma=(0.0, 0.2)),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Parameters\n",
    "    train_transform_params = {\n",
    "        \"image_size\": 128,\n",
    "        \"batch_size\": 32,\n",
    "        \"nclasses\": 2,\n",
    "        \"nchannels\": 1,\n",
    "        \"name\": \"axial\",\n",
    "        \"samples_per_epoch\": None,\n",
    "        \"transform\": augmentation,\n",
    "    }\n",
    "\n",
    "    valid_transform_params = {\n",
    "        \"image_size\": 128,\n",
    "        \"batch_size\": 32,\n",
    "        \"nclasses\": 2,\n",
    "        \"nchannels\": 1,\n",
    "        \"name\": \"axial\",\n",
    "        \"samples_per_epoch\": None,\n",
    "        \"transform\": None,\n",
    "    }\n",
    "\n",
    "    # Generators\n",
    "    training_generator = DataGeneratoronFly(data_csv=csv_path, **train_transform_params)\n",
    "    \n",
    "#     X, Y - (133*32, 128, 128, 1) (133*32)\n",
    "    \n",
    "    # print (training_generator.__len__())\n",
    "\n",
    "#     validation_generator = DataGeneratoronFly(data_csv=csv_path, **valid_transform_params)\n",
    "#     print(validation_generator.__len__())\n",
    "    \n",
    "#     print(training_generator[0][0].shape)\n",
    "#     print(training_generator[0][1].shape)\n",
    "\n",
    "    \n",
    "#     train_dataset = tf.data.Dataset.from_tensor_slices(training_generator)\n",
    "    \n",
    "#     for X, y in training_generator:\n",
    "#         print (X.shape, y.shape)\n",
    "#         print (y[:4])\n",
    "#         imshow(X[0,:,:,64, 0], X[1,:,:,64, 0], X[2,:,:,64, 0], X[3,:,:,64, 0])\n",
    "        \n",
    "        \n",
    "#     for ep in range(5):\n",
    "#         print (\"============================\")\n",
    "#         for X, y in validation_generator:\n",
    "#             print (X.shape, y.shape)\n",
    "#             print (y[:4])\n",
    "\t\t# imshow(X[0,:,:,64, 0], X[1,:,:,64, 0], X[2,:,:,64, 0], X[3,:,:,64, 0])\n",
    "        \n",
    "\n",
    "#     import time\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     for i, (X, y) in enumerate(validation_generator):\n",
    "#         elapsed_time = time.time() - start_time\n",
    "#         start_time = time.time()\n",
    "#         plt.subplot(1, 3, 1)\n",
    "#         plt.imshow(X[0][0][:, :, 0])\n",
    "#         plt.subplot(1, 3, 2)\n",
    "#         plt.imshow(X[1][0][:, :, 0])\n",
    "#         plt.subplot(1, 3, 3)\n",
    "#         plt.imshow(X[2][0][:, :, 0])\n",
    "#         plt.title(str(y[0]))\n",
    "#         plt.savefig(str(i) + \"_.png\")\n",
    "#         print(y, type(X))\n",
    "#         print(X[0].shape, X[1].shape, X[2].shape)\n",
    "#         print(i, \"Elapsed Time\", np.round(elapsed_time, decimals=2), \"seconds\")\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tensorflow>=2.0.0 must be installed but found version 1.14.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-149bb96bf30c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnobrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnobrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nobrainer/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     raise ValueError(\n\u001b[1;32m     22\u001b[0m         \"tensorflow>=2.0.0 must be installed but found version {}\".format(\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         )\n\u001b[1;32m     25\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: tensorflow>=2.0.0 must be installed but found version 1.14.0"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import nobrainer\n",
    "from nobrainer import dataset, volume\n",
    "\n",
    "dir_path = os.path.abspath(\"csv/faced_defaced/train_test_fold_1/csv/\")\n",
    "csv_path = os.path.join(dir_path, \"training.csv\")\n",
    "# print(dir_path, csv_path)\n",
    "\n",
    "\n",
    "labels = pd.read_csv(csv_path)[\"Y\"].values\n",
    "paths = pd.read_csv(csv_path)[\"X\"].values\n",
    "\n",
    "\n",
    "# print(labels)\n",
    "\n",
    "n_classes=2\n",
    "volume_shape = (256, 256, 256)\n",
    "block_shape = (128, 128, 128)\n",
    "\n",
    "\n",
    "training_paths = zip(paths, labels)\n",
    "\n",
    "print(training_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('..')\n",
    "from helpers.utils import load_vol, save_vol\n",
    "from preprocessing.normalization import standardize_volume, normalize_volume\n",
    "from preprocessing.conform import conform_data\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "orig_data_face   = '/work/01329/poldrack/data/mriqc-net/face/T1w'\n",
    "orig_data_deface = '/work/01329/poldrack/data/mriqc-net/defaced'\n",
    "\n",
    "save_data_face   = '/work/01329/poldrack/data/mriqc-net/face/derivatives/conformed'\n",
    "save_data_deface = '/work/01329/poldrack/data/mriqc-net/defaced/derivatives/conformed'\n",
    "os.makedirs(save_data_face, exist_ok=True)\n",
    "os.makedirs(save_data_deface, exist_ok=True)\n",
    "\n",
    "# os.listdir(save_data_face)\n",
    "conform_size = (64, 64, 64)\n",
    "\n",
    "def preprocess(pth):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    filename = pth.split('/')[-1]\n",
    "    volume = conform_data(pth, conform_size)\n",
    "\n",
    "    volume = normalize_volume(standardize_volume(volume))\n",
    "    save_path = os.path.join(save_data_face, filename)\n",
    "\n",
    "    newaffine = np.eye(4)\n",
    "    newaffine[:3, 3] = -0.5 * (np.array(out_size) - 1)\n",
    "    nii = nib.Nifti1Image(volume, newaffine, None)\n",
    "    nii.to_filename(save_path)\n",
    "    return save_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
