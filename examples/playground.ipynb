{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import nobrainer\n",
    "from nobrainer import dataset, volume\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "dir_path = os.path.abspath(\"csv/faced_defaced/train_test_fold_1/csv/\")\n",
    "csv_path = os.path.join(dir_path, \"training.csv\")\n",
    "# print(dir_path, csv_path)\n",
    "\n",
    "\n",
    "labels = pd.read_csv(csv_path)[\"Y\"].values\n",
    "paths = pd.read_csv(csv_path)[\"X\"].values\n",
    "\n",
    "\n",
    "# print(labels)\n",
    "\n",
    "n_classes=2\n",
    "volume_shape = (256, 256, 256)\n",
    "block_shape = (128, 128, 128)\n",
    "\n",
    "\n",
    "training_paths = zip(paths, labels)\n",
    "\n",
    "print(training_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/work/01329/poldrack/data/mriqc-net/data/masks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "orig_root_dir = '/work/01329/poldrack/data/mriqc-net/data'\n",
    "orig_face_defaced = os.path.join(orig_root_dir, 'masks')\n",
    "orig_data_deface = os.path.join(orig_root_dir, 'defaced')\n",
    "\n",
    "orig_reface_dir = '/work/06850/sbansal6/maverick2/mriqc-shared/refaced'\n",
    "save_orig_faced_root_dir = os.path.join(orig_reface_dir, 'orig_faced')\n",
    "\n",
    "simg_path = os.path.join(orig_reface_dir,'afni-latest.simg')\n",
    "print(simg_path)\n",
    "exclude = ['ds002033_anat', 'ds002149_anat', 'ds001928_anat', \n",
    "           'ds002247_anat', 'ds002001_anat', 'ds002316_anat',\n",
    "           'ds002076_anat', 'ds002156_anat']\n",
    "\n",
    "ds_root_paths = glob.glob(orig_face_defaced + '/*_anat*')\n",
    "\n",
    "processes = set()\n",
    "max_processes = 16\n",
    "\n",
    "for data_dir in ds_root_paths:\n",
    "    print(\"datadir: \", data_dir)\n",
    "    dd = data_dir.split('/')[-1]\n",
    "    save_dd_dir = os.path.join(save_orig_faced_root_dir, dd)\n",
    "    os.makedirs(save_dd_dir, exist_ok=True)\n",
    "    ds = glob.glob(data_dir + '/*_defaced.nii*')\n",
    "    \n",
    "    for vol in ds:\n",
    "        vol_name = vol.split('/')[-1].split('.')[0]\n",
    "        vol_save_path = os.path.join(save_dd_dir, vol_name)\n",
    "        os.makedirs(vol_save_path, exist_ok=True)\n",
    "        prefix_pre = vol_save_path\n",
    "        prefix = os.path.join(prefix_pre, vol_name + '_refaced.nii.gz')\n",
    "        print(\"Processing Volume: \", vol)\n",
    "        print(\"Save Path: \", prefix)\n",
    "        processes.add(subprocess.Popen([\"singularity\",\"exec\", simg_path, \"@afni_refacer_run\",\n",
    "                                        \"-input\", vol,\n",
    "                                        \"-mode_reface_plus\",\n",
    "                                        \"-prefix\", prefix\n",
    "                                       ]))\n",
    "        \n",
    "        if len(processes) >= max_processes:\n",
    "            os.wait()\n",
    "            processes.difference_update([\n",
    "                p for p in processes if p.poll() is not None])\n",
    "\n",
    "#     print(ds)\n",
    "# ds_paths = glob.glob(orig_face_defaced + '*_defaced.nii*')\n",
    "\n",
    "# ds_paths = glob.glob(orig_data_deface + '/*ds*anat*')\n",
    "\n",
    "            \n",
    "# for p in ds_paths:\n",
    "#     for ex in exclude:\n",
    "#         if ex not in p:\n",
    "#             print(p)\n",
    "\n",
    "#             ds = p.split('/')[-1]\n",
    "#             os.makedirs(os.path.join(save_root_dir, ds), exist_ok=True)\n",
    "\n",
    "#             volumes = glob.glob(p + '/*.nii*')\n",
    "#         #     print(volumes)\n",
    "\n",
    "#             for vol in volumes:\n",
    "#                 v = vol.split('/')[-1].split('.')[0]\n",
    "\n",
    "#                 prefix_pre = os.path.join(save_root_dir, ds, v)\n",
    "#                 os.makedirs(prefix_pre, exist_ok=True)\n",
    "#                 prefix = os.path.join(prefix_pre, v + '_refaced.nii.gz')\n",
    "#                 print(\"Processing Volume: \", vol)\n",
    "                \n",
    "#                 processes.add(subprocess.Popen([\"singularity\",\"exec\", simg_path, \"@afni_refacer_run\",\n",
    "#                                  \"-input\", vol,\n",
    "#                                  \"-mode_reface_plus\",\n",
    "#                                  \"-prefix\", prefix\n",
    "#                                 ]))\n",
    "                \n",
    "#                 if len(processes) >= max_processes:\n",
    "#                     os.wait()\n",
    "#                     processes.difference_update([\n",
    "#                         p for p in processes if p.poll() is not None])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "# matplotlib.use('Agg')\n",
    "import os, sys\n",
    "sys.path.append('../defacing')\n",
    "\n",
    "from preprocessing.normalization import clip, standardize, normalize\n",
    "from preprocessing.conform import conform_data\n",
    "from helpers.utils import load_vol, save_vol, is_gz_file\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "# matplotlib.use('Agg')\n",
    "import os, sys\n",
    "sys.path.append('../defacing')\n",
    "import subprocess\n",
    "\n",
    "from preprocessing.normalization import clip, standardize, normalize\n",
    "from preprocessing.conform import conform_data\n",
    "from helpers.utils import load_vol, save_vol, is_gz_file\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "\n",
    "\n",
    "include = ['ds000140_anat',\n",
    "           'ds000119_anat',\n",
    "           'ds000157_anat',\n",
    "           'ds002509_anat'\n",
    "          ]\n",
    "    \n",
    "    \n",
    "orig_root_dir = '/work/01329/poldrack/data/mriqc-net/data'\n",
    "orig_data_face = os.path.join(orig_root_dir, 'face/T1w')\n",
    "orig_data_mask = os.path.join(orig_root_dir, 'masks')\n",
    "\n",
    "orig_data_deface = os.path.join(orig_root_dir, 'defaced')\n",
    "\n",
    "save_root_dir = '/work/06850/sbansal6/maverick2/mriqc-shared/'\n",
    "\n",
    "orig_data_reface = '/work/06850/sbansal6/maverick2/mriqc-shared/refaced'\n",
    "save_orig_faced_root_dir = os.path.join(orig_reface_dir, 'orig_faced')\n",
    "\n",
    "\n",
    "save_preprocessing_face = os.path.join(save_root_dir, 'preprocessing/face')\n",
    "save_conformed_face = os.path.join(save_root_dir, 'conformed/face')\n",
    "\n",
    "save_preprocessing_deface = os.path.join(save_root_dir, 'preprocessing/deface')\n",
    "save_conformed_deface = os.path.join(save_root_dir, 'conformed/deface')\n",
    "\n",
    "save_preprocessing_face_defaced = os.path.join(save_root_dir, 'preprocessing/face_defaced')\n",
    "save_conformed_face_defaced = os.path.join(save_root_dir, 'conformed/face_defaced')\n",
    "\n",
    "save_preprocessing_face_refaced = os.path.join(save_root_dir, 'preprocessing/face_refaced')\n",
    "save_conformed_face_refaced = os.path.join(save_root_dir, 'conformed/face_refaced')\n",
    "\n",
    "# os.makedirs(save_preprocessing_face, exist_ok=True)\n",
    "os.makedirs(save_preprocessing_deface, exist_ok=True)\n",
    "# os.makedirs(save_conformed_face, exist_ok=True)\n",
    "os.makedirs(save_conformed_deface, exist_ok=True)\n",
    "\n",
    "conform_size = (64, 64, 64)\n",
    "conform_zoom = (4., 4., 4.)\n",
    "\n",
    "\n",
    "def preprocess(orig_vol_pth, conform_pth, preprocess_pth, DS=None, mask_path=None, debug=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    filename = orig_vol_pth.split('/')[-1]\n",
    "    volume, affine, _ = load_vol(orig_vol_pth)\n",
    "    \n",
    "    # Preprocessing\n",
    "    volume = clip(volume, q=90)\n",
    "    volume = normalize(volume)\n",
    "    volume = standardize(volume)\n",
    "    \n",
    "    # \n",
    "    save_preprocessing_path = os.path.join(preprocess_pth, filename)\n",
    "    save_conformed_path = os.path.join(conform_pth, filename)\n",
    "    \n",
    "    print(\"save_preprocessing_path: \", save_preprocessing_path)\n",
    "    print(\"save_conformed_path: \", save_conformed_path)\n",
    "    \n",
    "    save_vol(save_preprocessing_path, volume, affine)\n",
    "\n",
    "    def _plot(data):\n",
    "        f, axarr = plt.subplots(8, 8, figsize=(12, 12))\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                axarr[i, j].imshow(np.rot90(data[:, :, j + 8*i], 1))\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "#         plt.subplot(1, 3, 1)\n",
    "#         plt.imshow(np.rot90(np.mean(data, axis=0)))\n",
    "#         plt.subplot(1, 3, 2)\n",
    "#         plt.imshow(np.rot90(np.mean(data, axis=1)))\n",
    "#         plt.subplot(1, 3, 3)\n",
    "#         plt.imshow(np.rot90(np.mean(data, axis=2)))\n",
    "#         plt.show()\n",
    "        \n",
    "    conform_data(save_preprocessing_path, \n",
    "                 out_file=save_conformed_path, \n",
    "                 out_size=conform_size, \n",
    "                 out_zooms=conform_zoom)\n",
    "\n",
    "    if debug: _plot(load_vol(save_conformed_path)[0])\n",
    "    \n",
    "    if mask_path and DS:\n",
    "        mask = np.array(nib.load(mask_path).dataobj)\n",
    "        masked_volume = volume*mask\n",
    "\n",
    "        save_mpreprocessing_path = os.path.join(save_preprocessing_deface, DS, filename)\n",
    "        save_mconformed_path = os.path.join(save_conformed_deface, DS, filename)\n",
    "        \n",
    "        print(\"save_deface_preprocessing_path: \", save_mpreprocessing_path)\n",
    "        print(\"save_deface_conformed_path: \", save_mconformed_path)\n",
    "        \n",
    "#         os.makedirs(save_mpreprocessing_path, exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(save_mconformed_path), exist_ok=True)\n",
    "    \n",
    "#         save_mpreprocessing_path = os\n",
    "        \n",
    "        save_vol(save_mpreprocessing_path, masked_volume, affine)\n",
    "\n",
    "        conform_data(save_mpreprocessing_path, \n",
    "                 out_file=save_mconformed_path, \n",
    "                 out_size=conform_size, \n",
    "                 out_zooms=conform_zoom)        \n",
    "        \n",
    "        return save_conformed_path, save_mconformed_path\n",
    "\n",
    "    return save_conformed_path\n",
    "\n",
    "\n",
    "# for path in glob(orig_data_face + \"/ds000140_anat/*.nii*\"):\n",
    "# #     try:\n",
    "        \n",
    "#     vol_name = path.split(\"/\")[-1]\n",
    "#     DS = path.split(\"/\")[-2]\n",
    "\n",
    "#     # directories for saving preprocessed and conformed volumes\n",
    "#     ds_save_conform_path = os.path.join(save_conformed_face, DS)\n",
    "#     ds_save_preprocess_path = os.path.join(save_preprocessing_face, DS)\n",
    "\n",
    "#     # Get the mask path\n",
    "#     mask_path = glob(os.path.join(orig_data_mask, DS, vol_name.split('.')[0] + \"*_mask*\"))[0]\n",
    "\n",
    "#     print(\"Mask_path\", mask_path)\n",
    "\n",
    "#     if not os.path.exists(ds_save_conform_path):\n",
    "#         os.makedirs(ds_save_conform_path)\n",
    "\n",
    "#     if not os.path.exists(ds_save_preprocess_path):\n",
    "#         os.makedirs(ds_save_preprocess_path)\n",
    "\n",
    "#     # Check if volume is a proper gunzipped\n",
    "#     print(os.path.splitext(path)[1])\n",
    "#     print(\"Gzipped: \", is_gz_file(path))\n",
    "#     if os.path.splitext(path)[1] == \".gz\" and not is_gz_file(path):\n",
    "#         rename_file = os.path.splitext(vol_name)[0]\n",
    "#         fixed_gz_tmp = os.path.join(save_conformed_face, rename_file)\n",
    "#         print(\"Fixed GZIP File: \", fixed_gz_tmp)\n",
    "#         subprocess.call([\"cp\", path, fixed_gz_tmp])\n",
    "\n",
    "#         print(preprocess(fixed_gz_tmp,\n",
    "#                          ds_save_conform_path,\n",
    "#                          ds_save_preprocess_path,\n",
    "#                          mask_path = mask_path,\n",
    "#                          DS=DS\n",
    "#                         ))\n",
    "#         os.remove(fixed_gz_tmp)\n",
    "\n",
    "#     else:\n",
    "#         print(preprocess(path,\n",
    "#                          ds_save_conform_path,\n",
    "#                          ds_save_preprocess_path,\n",
    "#                          mask_path = mask_path,\n",
    "#                          DS=DS\n",
    "#                         ))\n",
    "#     except:\n",
    "#         print(\"Preprocessing incomplete. Exception occurred.\")\n",
    "#         pass\n",
    "\n",
    "\n",
    "# for ds in include:\n",
    "#     volumes = glob(os.path.join(save_orig_faced_root_dir, ds) + '/*defaced*/*refaced.nii*')\n",
    "    \n",
    "    \n",
    "for path in glob(save_orig_faced_root_dir + \"/*/*defaced*/*refaced.nii*\"):\n",
    "    try:\n",
    "\n",
    "        vol_name = path.split(\"/\")[-1]\n",
    "        DS = path.split(\"/\")[-3]\n",
    "#         print(vol_name, DS)\n",
    "        if DS in include:\n",
    "\n",
    "            # directories for saving preprocessed and conformed volumes\n",
    "            ds_save_conform_path = os.path.join(save_conformed_face_refaced, DS)\n",
    "            ds_save_preprocess_path = os.path.join(save_preprocessing_face_refaced, DS)\n",
    "\n",
    "            os.makedirs(ds_save_conform_path, exist_ok=True)\n",
    "            os.makedirs(ds_save_preprocess_path, exist_ok=True)\n",
    "\n",
    "            # Check if volume is a proper gunzipped\n",
    "            if not os.path.splitext(path)[1] == \".gz\" and is_gz_file(path):\n",
    "                rename_file = os.path.splitext(vol_name)[0]\n",
    "                fixed_gz_tmp = os.path.join(save_conformed_deface, rename_file)\n",
    "                print(fixed_gz_tmp)\n",
    "                subprocess.call([\"cp\", path, fixed_gz_tmp])\n",
    "\n",
    "                print(preprocess(fixed_gz_tmp,\n",
    "                                 ds_save_conform_path,\n",
    "                                 ds_save_preprocess_path,\n",
    "                                 DS=DS\n",
    "                                ))\n",
    "                os.remove(fixed_gz_tmp)\n",
    "\n",
    "            else:\n",
    "                print(preprocess(path,\n",
    "                                 ds_save_conform_path,\n",
    "                                 ds_save_preprocess_path,\n",
    "                                 DS=DS\n",
    "                                ))\n",
    "    except:\n",
    "        print(\"Preprocessing incomplete. Exception occurred.\")\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_root_dir = '/work/01329/poldrack/data/mriqc-net/data'\n",
    "orig_data_face = os.path.join(orig_root_dir, 'face/T1w')\n",
    "# orig_data_mask = os.path.join(orig_root_dir, 'masks')\n",
    "\n",
    "orig_data_deface = os.path.join(orig_root_dir, 'defaced')\n",
    "\n",
    "save_root_dir = '/work/06850/sbansal6/maverick2/mriqc-shared/'\n",
    "\n",
    "# save_preprocessing_face = os.path.join(save_root_dir, 'preprocessing/face')\n",
    "save_conformed_face = os.path.join(save_root_dir, 'conformed/face')\n",
    "\n",
    "save_preprocessing_deface = os.path.join(save_root_dir, 'preprocessing/deface')\n",
    "save_conformed_deface = os.path.join(save_root_dir, 'conformed/deface')\n",
    "\n",
    "save_conformed_face_defaced = os.path.join(save_root_dir, 'conformed/face_defaced')\n",
    "# os.makedirs(save_preprocessing_face, exist_ok=True)\n",
    "# os.makedirs(save_preprocessing_deface, exist_ok=True)\n",
    "# os.makedirs(save_conformed_face, exist_ok=True)\n",
    "# os.makedirs(save_conformed_deface, exist_ok=True)\n",
    "\n",
    "\n",
    "def checkNonConformed(orig_path, save_path):\n",
    "\n",
    "    conform = []\n",
    "    orig = []\n",
    "\n",
    "    for path in glob(save_path + \"/*/*.nii*\"):\n",
    "        tempname = path.split(\"/\")[-1]\n",
    "        ds = path.split(\"/\")[-2]\n",
    "        conform.append(ds + \"/\" + tempname)\n",
    "\n",
    "    print(\"Total Conformed: \", len(conform))\n",
    "\n",
    "    for path in glob(orig_path + \"/*/*.nii*\"):\n",
    "        tempname = path.split(\"/\")[-1]\n",
    "        ds = path.split(\"/\")[-2]\n",
    "        orig.append(ds + \"/\" + tempname)\n",
    "\n",
    "    print(\"Total Original: \", len(orig))\n",
    "\n",
    "    print(\"Total not conformed: \", len(orig) - len(conform))\n",
    "\n",
    "    count = 0\n",
    "    for f in orig:\n",
    "        exists = False\n",
    "        for fc in conform:\n",
    "            if fc in f:\n",
    "                exists = True\n",
    "        if not exists:\n",
    "            count += 1\n",
    "            print(\"Not conformed file: \", f)\n",
    "            \n",
    "\n",
    "            \n",
    "checkNonConformed(orig_data_face, save_conformed_face)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_C = []\n",
    "face_O = []\n",
    "\n",
    "for path in glob(save_data_face + \"/*/*.nii*\"):\n",
    "    tempname = path.split(\"/\")[-1]\n",
    "    ds = path.split(\"/\")[-2]\n",
    "    face_C.append(ds + '/' + tempname)\n",
    "\n",
    "print(len(face_C))\n",
    "# print(face_C)\n",
    "\n",
    "\n",
    "for path in glob(orig_data_face + \"/*/*.nii*\"):\n",
    "    tempname = path.split(\"/\")[-1]\n",
    "    ds = path.split(\"/\")[-2]\n",
    "    face_O.append(ds + '/' + tempname)\n",
    "\n",
    "print(len(face_O))\n",
    "# print(face_O)\n",
    "\n",
    "count = 0\n",
    "for f in face_O:\n",
    "    exists = False\n",
    "    for fc in face_C:\n",
    "        if fc in f:\n",
    "            exists = True\n",
    "    if not exists:\n",
    "        count += 1\n",
    "        print(f)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate n-fold CV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from shutil import *\n",
    "import subprocess\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "face_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/conformed/face\"\n",
    "deface_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/conformed/deface\"\n",
    "face_defaced_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/conformed/face_defaced\"\n",
    "face_refaced_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/conformed/face_refaced\"\n",
    "\n",
    "paths = []\n",
    "labels = []\n",
    "\n",
    "for path in glob(face_defaced_path + \"/*/*.nii*\"):\n",
    "    DS = path.split('/')[-2]\n",
    "    if DS in include:\n",
    "        paths.append(path)\n",
    "        labels.append(0)\n",
    "    \n",
    "# for path in glob(deface_path + \"/*/*.nii*\"):\n",
    "#     paths.append(path)\n",
    "#     labels.append(0)\n",
    "\n",
    "for path in glob(face_refaced_path + \"/*/*.nii*\"):\n",
    "    DS = path.split('/')[-2]\n",
    "    if DS in include:\n",
    "        paths.append(path)\n",
    "        labels.append(1)\n",
    "    \n",
    "# for path in glob(face_path + \"/*/*.nii*\"):\n",
    "#     paths.append(path)\n",
    "#     labels.append(1)\n",
    "    \n",
    "print(len(paths))\n",
    "print(len(labels))\n",
    "\n",
    "save_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/experiment_faced_refaced/exp_face_refaced/csv_F15\"\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"X\"] = paths\n",
    "df[\"Y\"] = labels\n",
    "df.to_csv(os.path.join(save_path, \"all.csv\"))\n",
    "\n",
    "SPLITS = 15\n",
    "skf = StratifiedKFold(n_splits=SPLITS)\n",
    "fold_no = 1\n",
    "\n",
    "for train_index, test_index in skf.split(paths, labels):\n",
    "    out_path = save_path + \"/train_test_fold_{}/csv/\".format(fold_no)\n",
    "\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    image_train, image_test = (\n",
    "        itemgetter(*train_index)(paths),\n",
    "        itemgetter(*test_index)(paths),\n",
    "    )\n",
    "    label_train, label_test = (\n",
    "        itemgetter(*train_index)(labels),\n",
    "        itemgetter(*test_index)(labels),\n",
    "    )\n",
    "\n",
    "    # image_train = [os.path.join(data_path, 'sub-' + str(pth) + '_T1w.nii.gz') for pth in image_train]\n",
    "    train_data = {\"X\": image_train, \"Y\": label_train}\n",
    "    df_train = pd.DataFrame(train_data)\n",
    "    df_train.to_csv(os.path.join(out_path, \"training.csv\"), index=False)\n",
    "\n",
    "    # image_test = [os.path.join(data_path, 'sub-' + str(pth) + '_T1w.nii.gz') for pth in image_test]\n",
    "    validation_data = {\"X\": image_test, \"Y\": label_test}\n",
    "    df_validation = pd.DataFrame(validation_data)\n",
    "    df_validation.to_csv(os.path.join(out_path, \"validation.csv\"), index=False)\n",
    "\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tfrecords for n-fold CV Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import nobrainer\n",
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from shutil import *\n",
    "import subprocess\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "\n",
    "SPLITS = 15\n",
    "\n",
    "for fold in range(15, SPLITS+1):\n",
    "    \n",
    "    dir_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/experiment_faced_refaced/exp_face_refaced/csv_F15/train_test_fold_{}/csv/\".format(fold)\n",
    "    tf_records_dir = \"/work/06850/sbansal6/maverick2/mriqc-shared/experiment_faced_refaced/exp_face_refaced/tfrecords_F15/tfrecords_fold_{}/\".format(fold)\n",
    "    os.makedirs(tf_records_dir, exist_ok=True)\n",
    "    \n",
    "    train_csv_path = os.path.join(dir_path, \"training.csv\")\n",
    "    valid_csv_path = os.path.join(dir_path, \"validation.csv\")\n",
    "    \n",
    "    train_paths = pd.read_csv(train_csv_path)[\"X\"].values\n",
    "    train_labels = pd.read_csv(train_csv_path)[\"Y\"].values\n",
    "    train_D = list(zip(train_paths, train_labels))\n",
    "    random.shuffle(train_D)\n",
    "#     print(train_D[0])\n",
    "    \n",
    "    valid_paths = pd.read_csv(valid_csv_path)[\"X\"].values\n",
    "    valid_labels = pd.read_csv(valid_csv_path)[\"Y\"].values\n",
    "    valid_D = list(zip(valid_paths, valid_labels))\n",
    "    random.shuffle(valid_D)\n",
    "    \n",
    "    train_write_path = os.path.join(tf_records_dir, 'data-train_shard-{shard:03d}.tfrec')\n",
    "    valid_write_path = os.path.join(tf_records_dir, 'data-valid_shard-{shard:03d}.tfrec')\n",
    "    \n",
    "    nobrainer.tfrecord.write(\n",
    "        features_labels=train_D,\n",
    "        filename_template=train_write_path,\n",
    "        examples_per_shard=3)\n",
    "    \n",
    "    nobrainer.tfrecord.write(\n",
    "        features_labels=valid_D,\n",
    "        filename_template=valid_write_path,\n",
    "        examples_per_shard=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from shutil import *\n",
    "import subprocess\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "face_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/conformed/face\"\n",
    "deface_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/conformed/deface\"\n",
    "\n",
    "face_defaced_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/conformed/face_defaced\"\n",
    "\n",
    "paths = []\n",
    "labels = []\n",
    "\n",
    "for path in glob(face_defaced_path + \"/*/*.nii*\"):\n",
    "    paths.append(path)\n",
    "    labels.append(0)\n",
    "    \n",
    "for path in glob(deface_path + \"/*/*.nii*\"):\n",
    "    paths.append(path)\n",
    "    labels.append(0)\n",
    "\n",
    "for path in glob(face_path + \"/*/*.nii*\"):\n",
    "    paths.append(path)\n",
    "    labels.append(1)\n",
    "    \n",
    "print(len(paths))\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "# print(paths)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(paths, labels, test_size=0.15, random_state=123)\n",
    "\n",
    "# print(X_train, y_train, stratify=True)\n",
    "\n",
    "save_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/experiment_data_all/csv_final\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "train_data = {\"X\": paths, \"Y\": labels}\n",
    "df_train = pd.DataFrame(train_data)\n",
    "df_train.to_csv(os.path.join(save_path, \"training.csv\"), index=False)\n",
    "\n",
    "# validation_data = {\"X\": X_test, \"Y\": y_test}\n",
    "# df_validation = pd.DataFrame(validation_data)\n",
    "# df_validation.to_csv(os.path.join(save_path, \"validation.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nobrainer\n",
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from shutil import *\n",
    "import subprocess\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "\n",
    "dir_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/experiment_data_all/csv_final\"\n",
    "tf_records_dir = \"/work/06850/sbansal6/maverick2/mriqc-shared/experiment_data_all/tfrecords_final\"\n",
    "os.makedirs(tf_records_dir, exist_ok=True)\n",
    "\n",
    "train_csv_path = os.path.join(dir_path, \"training.csv\")\n",
    "# valid_csv_path = os.path.join(dir_path, \"validation.csv\")\n",
    "\n",
    "train_paths = pd.read_csv(train_csv_path)[\"X\"].values\n",
    "train_labels = pd.read_csv(train_csv_path)[\"Y\"].values\n",
    "train_D = list(zip(train_paths, train_labels))\n",
    "random.shuffle(train_D)\n",
    "#     print(train_D[0])\n",
    "\n",
    "# valid_paths = pd.read_csv(valid_csv_path)[\"X\"].values\n",
    "# valid_labels = pd.read_csv(valid_csv_path)[\"Y\"].values\n",
    "# valid_D = list(zip(valid_paths, valid_labels))\n",
    "# random.shuffle(valid_D)\n",
    "\n",
    "train_write_path = os.path.join(tf_records_dir, 'data-train_shard-{shard:03d}.tfrec')\n",
    "# valid_write_path = os.path.join(tf_records_dir, 'data-valid_shard-{shard:03d}.tfrec')\n",
    "\n",
    "nobrainer.tfrecord.write(\n",
    "    features_labels=train_D,\n",
    "    filename_template=train_write_path,\n",
    "    examples_per_shard=3)\n",
    "\n",
    "# nobrainer.tfrecord.write(\n",
    "#     features_labels=valid_D,\n",
    "#     filename_template=valid_write_path,\n",
    "#     examples_per_shard=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.random.uniform((1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((8, 64, 64, 1), (8, 1)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "import nobrainer\n",
    "from nobrainer.io import _is_gzipped\n",
    "from nobrainer.volume import to_blocks\n",
    "import sys, os\n",
    "sys.path.append('../defacing')\n",
    "from preprocessing.augmentation import VolumeAugmentations, SliceAugmentations\n",
    "from helpers.utils import load_vol\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ROOTDIR = '/work/06850/sbansal6/maverick2/mriqc-shared/experiment_faced_refaced/exp_face_defaced/tfrecords_F15'\n",
    "DISTRIBUTION = load_vol('../defacing/helpers/distribution.nii.gz')[0]\n",
    "DISTRIBUTION /= DISTRIBUTION.sum()\n",
    "COM = np.unravel_index(int(np.sum(DISTRIBUTION.ravel()*np.arange(len(DISTRIBUTION.ravel())))/np.sum(DISTRIBUTION.ravel())), DISTRIBUTION.shape)\n",
    "\n",
    "\n",
    "# sampling from augmented distribution is same as augmenting the sampled points\n",
    "# augmenting distribution at every iteration is expensive, so this way\n",
    "sampler = lambda n, distribution = DISTRIBUTION, threshold = 0.1: np.array([ np.unravel_index(\n",
    "          np.random.choice(np.arange(np.prod(distribution.shape)),\n",
    "                                     p = distribution.ravel()),\n",
    "          distribution.shape) + (+1 if np.random.randn() > 0.5 else -1)*np.random.randint(0, \n",
    "                                        int(distribution.shape[0]*threshold) + 1, 3) for _ in range(n)]) \n",
    "\n",
    "\n",
    "three_d_augmentations = {'rotation': 0.5,\n",
    "                         'translation': 0.5,\n",
    "                         'noop': 0.3\n",
    "                        }\n",
    "\n",
    "augmentvolume = VolumeAugmentations(DISTRIBUTION, three_d_augmentations)\n",
    "\n",
    "two_d_augmentations = {'rotation': 0.5,\n",
    "                       'fliplr': 0.5,\n",
    "                       'flipud': 0.5,\n",
    "                       'zoom': 0.5,\n",
    "                       'noop': 0.3\n",
    "                      }\n",
    "\n",
    "# augmentslice = VolumeAugmentations(DISTRIBUTION, two_d_augmentations)\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    file_pattern,\n",
    "    n_classes,\n",
    "    batch_size,\n",
    "    volume_shape,\n",
    "    plane,\n",
    "    n = 24,\n",
    "    block_shape=None,\n",
    "    n_epochs=None,\n",
    "    mapping=None,\n",
    "    augment=False,\n",
    "    shuffle_buffer_size=None,\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    "):\n",
    "\n",
    "    \"\"\" Returns tf.data.Dataset after preprocessing from\n",
    "    tfrecords for training and validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_pattern:\n",
    "\n",
    "    n_classes:\n",
    "    \"\"\"\n",
    "\n",
    "    files = glob.glob(file_pattern)\n",
    "\n",
    "    if not files:\n",
    "        raise ValueError(\"no files found for pattern '{}'\".format(file_pattern))\n",
    "\n",
    "    compressed = _is_gzipped(files[0])\n",
    "    shuffle = bool(shuffle_buffer_size)\n",
    "\n",
    "    ds = nobrainer.dataset.tfrecord_dataset(\n",
    "        file_pattern=file_pattern,\n",
    "        volume_shape=volume_shape,\n",
    "        shuffle=shuffle,\n",
    "        scalar_label=True,\n",
    "        compressed=compressed,\n",
    "        num_parallel_calls=num_parallel_calls,\n",
    "    )\n",
    "\n",
    "    # if augment:\n",
    "    #     ds = ds.map(\n",
    "    #         lambda x, y: tf.cond(\n",
    "    #             tf.random.uniform((1,)) > 0.5,\n",
    "    #             true_fn=lambda: apply_augmentations(x, y),\n",
    "    #             false_fn=lambda: (x, y),\n",
    "    #         ),\n",
    "    #         num_parallel_calls=num_parallel_calls,\n",
    "    #     )\n",
    "\n",
    "    def _ss(x, y):\n",
    "        if augment:\n",
    "            if three_d_augmentations['noop'] < 1:\n",
    "                x, y = augmentvolume(x,y)\n",
    "        x, y = structural_slice(x, y, \n",
    "                                plane, \n",
    "                                n, \n",
    "                                augment, \n",
    "                                augmentvolume.distribution)\n",
    "        return (x, y)\n",
    "\n",
    "    ds = ds.map(_ss, num_parallel_calls)\n",
    "\n",
    "    #     def _f(x, y):\n",
    "    #         x = to_blocks(x, block_shape)\n",
    "    #         n_blocks = x.shape[0]\n",
    "    #         y = tf.repeat(y, n_blocks)\n",
    "    #         return (x, y)\n",
    "    #     ds = ds.map(_f, num_parallel_calls=num_parallel_calls)\n",
    "\n",
    "    # This step is necessary because it reduces the extra dimension.\n",
    "    # ds = ds.unbatch()\n",
    "\n",
    "\n",
    "    ds = ds.prefetch(buffer_size=batch_size)\n",
    "\n",
    "    if batch_size is not None:\n",
    "        ds = ds.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "    if shuffle_buffer_size:\n",
    "        ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat the dataset n_epochs times\n",
    "    ds = ds.repeat(n_epochs)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def structural_slice(x, y, \n",
    "                plane, \n",
    "                n = 4, \n",
    "                augment = False, \n",
    "                distribution = DISTRIBUTION):\n",
    "\n",
    "    \"\"\" Transpose dataset based on the plane\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x:\n",
    "\n",
    "    y:\n",
    "\n",
    "    plane:\n",
    "    \n",
    "    n:\n",
    "\n",
    "    augment:\n",
    "    \"\"\"\n",
    "\n",
    "    threshold = 0.1 if augment else 0.0 \n",
    "    options = [\"axial\", \"coronal\", \"sagittal\", \"combined\"]\n",
    "    shape = np.array(x.shape)\n",
    "\n",
    "    if isinstance(plane, str) and plane in options:\n",
    "        idxs = sampler(n, \n",
    "                        distribution, \n",
    "                        threshold)\n",
    "\n",
    "        if plane == \"axial\":\n",
    "            idx = np.random.randint(shape[0]**0.5)\n",
    "            midx = idxs[:, 0]\n",
    "            x = x\n",
    "\n",
    "        if plane == \"coronal\":\n",
    "            idx = np.random.randint(shape[1]**0.5)\n",
    "            midx = idxs[:, 1]\n",
    "            x = tf.transpose(x, perm=[1, 2, 0])\n",
    "\n",
    "\n",
    "        if plane == \"sagittal\":\n",
    "            idx = np.random.randint(shape[2]**0.5)\n",
    "            midx = idxs[:, 2]\n",
    "            x = tf.transpose(x, perm=[2, 0, 1])\n",
    "\n",
    "\n",
    "        if plane == \"combined\":\n",
    "            temp = {}\n",
    "            for op in options[:-1]:\n",
    "                temp[op] = structural_slice(x, y, \n",
    "                                            op, \n",
    "                                            n, \n",
    "                                            augment, \n",
    "                                            distribution)[0]\n",
    "            x = temp\n",
    "\n",
    "        if not plane == \"combined\":\n",
    "            x = tf.squeeze(tf.gather_nd(x, midx.reshape(n, 1, 1)), axis=1)\n",
    "            x = tf.math.reduce_mean(x, axis=0)\n",
    "            x = tf.expand_dims(x, axis=-1)\n",
    "            \n",
    "            if augment:\n",
    "                x = two_d_augmentations(x)\n",
    "                \n",
    "            x = tf.convert_to_tensor(x)\n",
    "        return x, y\n",
    "    else:\n",
    "        raise ValueError(\"expected plane to be one of ['axial', 'coronal', 'sagittal']\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    n_classes = 2\n",
    "    global_batch_size = 8\n",
    "    volume_shape = (64, 64, 64)\n",
    "    ds = get_dataset(\n",
    "        os.path.join(ROOTDIR, \"tfrecords_fold_1/data-train_*\"),\n",
    "        n_classes=n_classes,\n",
    "        batch_size=global_batch_size,\n",
    "        volume_shape=volume_shape,\n",
    "        plane=\"sagittal\",\n",
    "        augment = False,\n",
    "        shuffle_buffer_size=3,\n",
    "    )\n",
    "\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(ds)\n",
    "#     for ii in range(100):\n",
    "#         x,y=next(ds.as_numpy_iterator())\n",
    "#         # print (np.min(x), np.max(x), np.unique(y))\n",
    "#         count = 1\n",
    "#         for i in range(global_batch_size):\n",
    "#             for key in x.keys():\n",
    "#                 plt.subplot(global_batch_size, 3, count)\n",
    "#                 plt.imshow(x[key][i, :, :, 0])\n",
    "#                 plt.title(str(y[i]))\n",
    "#                 plt.xticks([],\" \")\n",
    "#                 plt.yticks([], \" \")\n",
    "#                 count += 1\n",
    "#         plt.savefig(\"processed_image_combined_{}.png\".format(ii))\n",
    "\n",
    "\n",
    "# dataset_train_coronal = get_dataset(\"tfrecords/tfrecords_fold_1/data-train_*\",\n",
    "#                             n_classes=n_classes,\n",
    "#                             batch_size=global_batch_size,\n",
    "#                             volume_shape=volume_shape,\n",
    "#                             block_shape=block_shape,\n",
    "#                             plane='coronal',\n",
    "#                             shuffle_buffer_size=3)\n",
    "\n",
    "# dataset_train_sagittal = get_dataset(\"tfrecords/tfrecords_fold_1/data-train_*\",\n",
    "#                             n_classes=n_classes,\n",
    "#                             batch_size=global_batch_size,\n",
    "#                             volume_shape=volume_shape,\n",
    "#                             block_shape=block_shape,\n",
    "#                             plane='sagittal',\n",
    "#                             shuffle_buffer_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "{0: 1.0, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fold = 1\n",
    "ROOTDIR = '/work/06850/sbansal6/maverick2/mriqc-shared/experiment_faced_refaced/exp_face_defaced/tfrecords_F15'\n",
    "dir_path = \"/work/06850/sbansal6/maverick2/mriqc-shared/experiment_faced_refaced/exp_face_defaced/csv_F15/train_test_fold_{}/csv/\".format(fold)\n",
    "\n",
    "train_csv_path = os.path.join(dir_path, \"training.csv\")\n",
    "valid_csv_path = os.path.join(dir_path, \"validation.csv\")\n",
    "\n",
    "train_paths = pd.read_csv(train_csv_path)[\"X\"].values\n",
    "valid_paths = pd.read_csv(valid_csv_path)[\"X\"].values\n",
    "\n",
    "train_labels = pd.read_csv(train_csv_path)[\"Y\"].values\n",
    "valid_labels = pd.read_csv(valid_csv_path)[\"Y\"].values\n",
    "\n",
    "print(type(train_labels))\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            np.unique(train_labels),\n",
    "                                            train_labels)\n",
    "\n",
    "print(dict(enumerate(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 176ms/step - loss: 0.6604 - tp: 121.0000 - fp: 37.0000 - tn: 124.0000 - fn: 38.0000 - accuracy: 0.7656 - precision: 0.7658 - recall: 0.7610 - auc: 0.8257 - val_loss: 0.6450 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0553 - tp: 156.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 5.0000 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9689 - auc: 0.9978 - val_loss: 0.6546 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0242 - tp: 152.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 3.0000 - accuracy: 0.9906 - precision: 1.0000 - recall: 0.9806 - auc: 0.9998 - val_loss: 0.7757 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.0089 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7179 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0042 - tp: 175.0000 - fp: 0.0000e+00 - tn: 145.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8368 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0048 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9321 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0011 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2418 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0011 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1111 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 6.4697e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1124 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 4.4371e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1386 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 4.9139e-04 - tp: 171.0000 - fp: 0.0000e+00 - tn: 149.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0315 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 5.0187e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3146 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 3.3395e-04 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0879 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 4.0781e-04 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6798 - val_tp: 15.0000 - val_fp: 12.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5556 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 3.1175e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5173 - val_tp: 17.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6296 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 182ms/step - loss: 1.0208 - tp: 106.0000 - fp: 42.0000 - tn: 121.0000 - fn: 51.0000 - accuracy: 0.7094 - precision: 0.7162 - recall: 0.6752 - auc: 0.7766 - val_loss: 0.6429 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8824 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1826 - tp: 151.0000 - fp: 9.0000 - tn: 149.0000 - fn: 11.0000 - accuracy: 0.9375 - precision: 0.9438 - recall: 0.9321 - auc: 0.9755 - val_loss: 0.6108 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0712 - tp: 155.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 7.0000 - accuracy: 0.9781 - precision: 1.0000 - recall: 0.9568 - auc: 0.9962 - val_loss: 0.6381 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.0536 - tp: 156.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 4.0000 - accuracy: 0.9875 - precision: 1.0000 - recall: 0.9750 - auc: 0.9974 - val_loss: 0.6487 - val_tp: 12.0000 - val_fp: 2.0000 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8571 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0434 - tp: 160.0000 - fp: 1.0000 - tn: 157.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9938 - recall: 0.9877 - auc: 0.9981 - val_loss: 0.6464 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 43ms/step - loss: 0.0241 - tp: 154.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 3.0000 - accuracy: 0.9906 - precision: 1.0000 - recall: 0.9809 - auc: 0.9999 - val_loss: 0.6665 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0347 - tp: 156.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 5.0000 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9689 - auc: 0.9995 - val_loss: 0.6093 - val_tp: 20.0000 - val_fp: 12.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0138 - tp: 153.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9871 - auc: 1.0000 - val_loss: 0.6154 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0308 - tp: 169.0000 - fp: 2.0000 - tn: 146.0000 - fn: 3.0000 - accuracy: 0.9844 - precision: 0.9883 - recall: 0.9826 - auc: 0.9997 - val_loss: 0.6064 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0148 - tp: 153.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9935 - auc: 1.0000 - val_loss: 0.6482 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0069 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6754 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0032 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5728 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0019 - tp: 148.0000 - fp: 0.0000e+00 - tn: 172.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5012 - val_tp: 16.0000 - val_fp: 15.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5161 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0018 - tp: 172.0000 - fp: 0.0000e+00 - tn: 148.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4650 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5185 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0014 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4121 - val_tp: 13.0000 - val_fp: 5.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.7222 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.7720 - tp: 129.0000 - fp: 29.0000 - tn: 128.0000 - fn: 34.0000 - accuracy: 0.8031 - precision: 0.8165 - recall: 0.7914 - auc: 0.8535 - val_loss: 0.6913 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9980\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0474 - tp: 153.0000 - fp: 2.0000 - tn: 162.0000 - fn: 3.0000 - accuracy: 0.9844 - precision: 0.9871 - recall: 0.9808 - auc: 0.9989 - val_loss: 0.6690 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0133 - tp: 162.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9939 - auc: 1.0000 - val_loss: 0.6768 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.0073 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7088 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0021 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7064 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0014 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6999 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0012 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6635 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 5.7779e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5153 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 5.2206e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4269 - val_tp: 8.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.7188 - val_precision: 1.0000 - val_recall: 0.4706 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 4.8992e-04 - tp: 149.0000 - fp: 0.0000e+00 - tn: 171.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2400 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 38ms/step - loss: 6.5171e-04 - tp: 170.0000 - fp: 0.0000e+00 - tn: 150.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1292 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 3.5081e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0687 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 4.4959e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0381 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 2.7558e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0291 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 3.7789e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0140 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 5s 262ms/step - loss: 1.3160 - tp: 117.0000 - fp: 43.0000 - tn: 116.0000 - fn: 44.0000 - accuracy: 0.7281 - precision: 0.7312 - recall: 0.7267 - auc: 0.7840 - val_loss: 0.6662 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9902\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.0901 - tp: 161.0000 - fp: 3.0000 - tn: 152.0000 - fn: 4.0000 - accuracy: 0.9781 - precision: 0.9817 - recall: 0.9758 - auc: 0.9915 - val_loss: 0.6785 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0246 - tp: 151.0000 - fp: 2.0000 - tn: 165.0000 - fn: 2.0000 - accuracy: 0.9875 - precision: 0.9869 - recall: 0.9869 - auc: 0.9998 - val_loss: 0.6665 - val_tp: 15.0000 - val_fp: 10.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 0.9647\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0298 - tp: 158.0000 - fp: 1.0000 - tn: 158.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9937 - recall: 0.9814 - auc: 0.9993 - val_loss: 0.7568 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9275\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0036 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6733 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.0136 - tp: 163.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9879 - auc: 0.9999 - val_loss: 0.7775 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9882\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0020 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8567 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.9960\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.0031 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7579 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.9980\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0014 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8190 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0012 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8108 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0016 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7352 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0031 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8559 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.0018 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6693 - val_tp: 17.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5484 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 9.3974e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4662 - val_tp: 18.0000 - val_fp: 8.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.6923 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 5.9490e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4464 - val_tp: 16.0000 - val_fp: 9.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7188 - val_precision: 0.6400 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.6713 - tp: 123.0000 - fp: 25.0000 - tn: 137.0000 - fn: 35.0000 - accuracy: 0.8125 - precision: 0.8311 - recall: 0.7785 - auc: 0.8663 - val_loss: 0.6709 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0378 - tp: 156.0000 - fp: 3.0000 - tn: 159.0000 - fn: 2.0000 - accuracy: 0.9844 - precision: 0.9811 - recall: 0.9873 - auc: 0.9990 - val_loss: 0.6900 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0086 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8409 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0054 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7528 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0029 - tp: 151.0000 - fp: 0.0000e+00 - tn: 169.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8617 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0020 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7471 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 8.5139e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8906 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0011 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7593 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 6.9316e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9337 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 9.7903e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8495 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0010 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8491 - val_tp: 13.0000 - val_fp: 19.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4062 - val_precision: 0.4062 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 6.8568e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7018 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 3.3226e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5292 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 3.9165e-04 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4009 - val_tp: 16.0000 - val_fp: 9.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7188 - val_precision: 0.6400 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 3.8488e-04 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2969 - val_tp: 15.0000 - val_fp: 3.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 188ms/step - loss: 0.9336 - tp: 125.0000 - fp: 36.0000 - tn: 123.0000 - fn: 36.0000 - accuracy: 0.7750 - precision: 0.7764 - recall: 0.7764 - auc: 0.8165 - val_loss: 0.6602 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0708 - tp: 150.0000 - fp: 3.0000 - tn: 162.0000 - fn: 5.0000 - accuracy: 0.9750 - precision: 0.9804 - recall: 0.9677 - auc: 0.9967 - val_loss: 0.6347 - val_tp: 18.0000 - val_fp: 1.0000 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9474 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0636 - tp: 157.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 6.0000 - accuracy: 0.9812 - precision: 1.0000 - recall: 0.9632 - auc: 0.9966 - val_loss: 0.6504 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.0366 - tp: 147.0000 - fp: 1.0000 - tn: 171.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9932 - recall: 0.9932 - auc: 0.9994 - val_loss: 0.6229 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0195 - tp: 171.0000 - fp: 0.0000e+00 - tn: 147.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9884 - auc: 1.0000 - val_loss: 0.6001 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0080 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6844 - val_tp: 13.0000 - val_fp: 19.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4062 - val_precision: 0.4062 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0041 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5900 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0036 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5266 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0014 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4384 - val_tp: 18.0000 - val_fp: 10.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6429 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 8.5565e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4229 - val_tp: 16.0000 - val_fp: 10.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6154 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 38ms/step - loss: 6.1171e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3778 - val_tp: 17.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6296 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 7.4517e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3735 - val_tp: 16.0000 - val_fp: 8.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 5.2457e-04 - tp: 174.0000 - fp: 0.0000e+00 - tn: 146.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4301 - val_tp: 15.0000 - val_fp: 10.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.0016 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6810 - val_tp: 17.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5484 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0013 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3330 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7273 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 0.4846 - tp: 138.0000 - fp: 18.0000 - tn: 144.0000 - fn: 20.0000 - accuracy: 0.8813 - precision: 0.8846 - recall: 0.8734 - auc: 0.9318 - val_loss: 0.7059 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6333\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0405 - tp: 156.0000 - fp: 1.0000 - tn: 159.0000 - fn: 4.0000 - accuracy: 0.9844 - precision: 0.9936 - recall: 0.9750 - auc: 0.9991 - val_loss: 0.6893 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7647\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0039 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6883 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9706\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.0033 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7061 - val_tp: 13.0000 - val_fp: 19.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4062 - val_precision: 0.4062 - val_recall: 1.0000 - val_auc: 0.9555\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0063 - tp: 168.0000 - fp: 1.0000 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 0.9969 - precision: 0.9941 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6888 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9609\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0012 - tp: 148.0000 - fp: 0.0000e+00 - tn: 172.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6944 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 0.9802\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 9.5092e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6705 - val_tp: 4.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 12.0000 - val_accuracy: 0.6250 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.9961\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 5.6256e-04 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6504 - val_tp: 18.0000 - val_fp: 13.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5806 - val_recall: 1.0000 - val_auc: 0.9960\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 1.9133e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6421 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.9960\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 8.2586e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6819 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 4.6883e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5983 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 2.9951e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5533 - val_tp: 16.0000 - val_fp: 7.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.6957 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 2.3778e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5232 - val_tp: 14.0000 - val_fp: 7.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 2.3736e-04 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4362 - val_tp: 18.0000 - val_fp: 4.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8182 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 2.4000e-04 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3564 - val_tp: 18.0000 - val_fp: 6.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7500 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 5s 271ms/step - loss: 2.0313 - tp: 104.0000 - fp: 67.0000 - tn: 93.0000 - fn: 56.0000 - accuracy: 0.6156 - precision: 0.6082 - recall: 0.6500 - auc: 0.6820 - val_loss: 0.6897 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 1.0000 - val_recall: 0.1053 - val_auc: 0.8462\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.1507 - tp: 139.0000 - fp: 4.0000 - tn: 161.0000 - fn: 16.0000 - accuracy: 0.9375 - precision: 0.9720 - recall: 0.8968 - auc: 0.9865 - val_loss: 0.6745 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9843\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0784 - tp: 161.0000 - fp: 2.0000 - tn: 151.0000 - fn: 6.0000 - accuracy: 0.9750 - precision: 0.9877 - recall: 0.9641 - auc: 0.9952 - val_loss: 0.6645 - val_tp: 17.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.6800 - val_recall: 1.0000 - val_auc: 0.9706\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0240 - tp: 153.0000 - fp: 1.0000 - tn: 164.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9935 - recall: 0.9871 - auc: 0.9997 - val_loss: 0.6659 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9451\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0233 - tp: 161.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9877 - auc: 1.0000 - val_loss: 0.6308 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.9762\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0231 - tp: 158.0000 - fp: 1.0000 - tn: 158.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9937 - recall: 0.9814 - auc: 0.9998 - val_loss: 0.6028 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 5.0000 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.6875 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0050 - tp: 147.0000 - fp: 0.0000e+00 - tn: 173.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5875 - val_tp: 16.0000 - val_fp: 4.0000 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.0059 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5691 - val_tp: 15.0000 - val_fp: 13.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5357 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0015 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4912 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0039 - tp: 150.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5067 - val_tp: 14.0000 - val_fp: 12.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5385 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0032 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4785 - val_tp: 15.0000 - val_fp: 12.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5556 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.0025 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3373 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 69ms/step - loss: 0.0039 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2853 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0021 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3220 - val_tp: 15.0000 - val_fp: 2.0000 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0011 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2556 - val_tp: 16.0000 - val_fp: 2.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 181ms/step - loss: 0.9394 - tp: 130.0000 - fp: 37.0000 - tn: 120.0000 - fn: 33.0000 - accuracy: 0.7812 - precision: 0.7784 - recall: 0.7975 - auc: 0.8338 - val_loss: 0.6835 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.7143\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0479 - tp: 155.0000 - fp: 2.0000 - tn: 160.0000 - fn: 3.0000 - accuracy: 0.9844 - precision: 0.9873 - recall: 0.9810 - auc: 0.9991 - val_loss: 0.7257 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.8745\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0163 - tp: 156.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9936 - auc: 0.9999 - val_loss: 0.7665 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.5357\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0048 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7861 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 0.9777\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0024 - tp: 171.0000 - fp: 0.0000e+00 - tn: 149.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0958 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9843\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0048 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0932 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0035 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1976 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 9.5300e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1823 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0015 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.4294 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 6.5308e-04 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1785 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 3.0600e-04 - tp: 145.0000 - fp: 0.0000e+00 - tn: 175.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9539 - val_tp: 20.0000 - val_fp: 12.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 3.0811e-04 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0546 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 2.3258e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6146 - val_tp: 18.0000 - val_fp: 11.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6562 - val_precision: 0.6207 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 7.7106e-04 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7256 - val_tp: 15.0000 - val_fp: 14.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5172 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 7.7757e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2241 - val_tp: 15.0000 - val_fp: 5.0000 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.7500 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.7407 - tp: 123.0000 - fp: 39.0000 - tn: 119.0000 - fn: 39.0000 - accuracy: 0.7563 - precision: 0.7593 - recall: 0.7593 - auc: 0.8448 - val_loss: 0.6956 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.1004 - tp: 156.0000 - fp: 3.0000 - tn: 155.0000 - fn: 6.0000 - accuracy: 0.9719 - precision: 0.9811 - recall: 0.9630 - auc: 0.9877 - val_loss: 0.7443 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 20.0000 - val_accuracy: 0.3750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9500\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0879 - tp: 161.0000 - fp: 3.0000 - tn: 150.0000 - fn: 6.0000 - accuracy: 0.9719 - precision: 0.9817 - recall: 0.9641 - auc: 0.9926 - val_loss: 0.7074 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8902\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.0566 - tp: 152.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 6.0000 - accuracy: 0.9812 - precision: 1.0000 - recall: 0.9620 - auc: 0.9971 - val_loss: 0.7908 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 19.0000 - val_accuracy: 0.4062 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9271\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0624 - tp: 147.0000 - fp: 1.0000 - tn: 165.0000 - fn: 7.0000 - accuracy: 0.9750 - precision: 0.9932 - recall: 0.9545 - auc: 0.9954 - val_loss: 0.7585 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9921\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0449 - tp: 169.0000 - fp: 1.0000 - tn: 147.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9941 - recall: 0.9826 - auc: 0.9981 - val_loss: 0.7628 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9980\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0685 - tp: 152.0000 - fp: 5.0000 - tn: 160.0000 - fn: 3.0000 - accuracy: 0.9750 - precision: 0.9682 - recall: 0.9806 - auc: 0.9953 - val_loss: 0.8937 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9843\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0430 - tp: 164.0000 - fp: 1.0000 - tn: 151.0000 - fn: 4.0000 - accuracy: 0.9844 - precision: 0.9939 - recall: 0.9762 - auc: 0.9985 - val_loss: 0.6590 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0144 - tp: 147.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 3.0000 - accuracy: 0.9906 - precision: 1.0000 - recall: 0.9800 - auc: 1.0000 - val_loss: 0.6433 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0054 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7885 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0087 - tp: 170.0000 - fp: 0.0000e+00 - tn: 150.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5769 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.0588 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0042 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4919 - val_tp: 5.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 11.0000 - val_accuracy: 0.6562 - val_precision: 1.0000 - val_recall: 0.3125 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0033 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3622 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 4.0000 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.7500 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 6.9938e-04 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1726 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9333 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 8.8039e-04 - tp: 150.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1296 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.7321 - tp: 122.0000 - fp: 29.0000 - tn: 134.0000 - fn: 35.0000 - accuracy: 0.8000 - precision: 0.8079 - recall: 0.7771 - auc: 0.8900 - val_loss: 0.6926 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7412\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0468 - tp: 163.0000 - fp: 5.0000 - tn: 151.0000 - fn: 1.0000 - accuracy: 0.9812 - precision: 0.9702 - recall: 0.9939 - auc: 0.9992 - val_loss: 0.6898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7863\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0220 - tp: 148.0000 - fp: 1.0000 - tn: 169.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9933 - recall: 0.9867 - auc: 0.9998 - val_loss: 0.6939 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6508\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.0088 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6889 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.6765\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0025 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6891 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 1.0000 - val_recall: 0.1176 - val_auc: 0.9118\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0016 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6875 - val_tp: 14.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 3.0000 - val_accuracy: 0.8750 - val_precision: 0.9333 - val_recall: 0.8235 - val_auc: 0.9314\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0012 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6871 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.8477\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0016 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6799 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.7917\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 7.2030e-04 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6648 - val_tp: 20.0000 - val_fp: 12.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000 - val_auc: 0.9250\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 9.2845e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6598 - val_tp: 17.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5667 - val_recall: 1.0000 - val_auc: 0.9941\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 7.8064e-04 - tp: 173.0000 - fp: 0.0000e+00 - tn: 147.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6396 - val_tp: 17.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5862 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 6.2643e-04 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5886 - val_tp: 17.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6296 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 5.9219e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5573 - val_tp: 15.0000 - val_fp: 6.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7143 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 8.1017e-04 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4683 - val_tp: 16.0000 - val_fp: 2.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 4.8671e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4339 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 5s 257ms/step - loss: 1.3500 - tp: 124.0000 - fp: 36.0000 - tn: 123.0000 - fn: 37.0000 - accuracy: 0.7719 - precision: 0.7750 - recall: 0.7702 - auc: 0.8161 - val_loss: 0.6644 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0946 - tp: 146.0000 - fp: 2.0000 - tn: 168.0000 - fn: 4.0000 - accuracy: 0.9812 - precision: 0.9865 - recall: 0.9733 - auc: 0.9865 - val_loss: 0.6464 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 4.0000 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.7500 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0360 - tp: 156.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 3.0000 - accuracy: 0.9906 - precision: 1.0000 - recall: 0.9811 - auc: 0.9988 - val_loss: 0.6498 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0305 - tp: 159.0000 - fp: 1.0000 - tn: 157.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9937 - recall: 0.9815 - auc: 0.9996 - val_loss: 0.6322 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0086 - tp: 160.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9938 - auc: 1.0000 - val_loss: 0.6149 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0079 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6030 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0037 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6566 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0031 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5479 - val_tp: 14.0000 - val_fp: 6.0000 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0027 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5557 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0022 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4275 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0037 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6142 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0030 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3308 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 64ms/step - loss: 7.0908e-04 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1879 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 0.0014 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2142 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 9.0157e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1696 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 1.0266 - tp: 122.0000 - fp: 46.0000 - tn: 111.0000 - fn: 41.0000 - accuracy: 0.7281 - precision: 0.7262 - recall: 0.7485 - auc: 0.7980 - val_loss: 0.6577 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0748 - tp: 149.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 7.0000 - accuracy: 0.9781 - precision: 1.0000 - recall: 0.9551 - auc: 0.9957 - val_loss: 0.6669 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9608\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0311 - tp: 157.0000 - fp: 2.0000 - tn: 158.0000 - fn: 3.0000 - accuracy: 0.9844 - precision: 0.9874 - recall: 0.9812 - auc: 0.9996 - val_loss: 0.6589 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0044 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6511 - val_tp: 15.0000 - val_fp: 6.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7143 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0069 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6317 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0033 - tp: 172.0000 - fp: 0.0000e+00 - tn: 148.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6025 - val_tp: 16.0000 - val_fp: 15.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5161 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0021 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5922 - val_tp: 13.0000 - val_fp: 15.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.4643 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0017 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4902 - val_tp: 16.0000 - val_fp: 7.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.6957 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0017 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4918 - val_tp: 15.0000 - val_fp: 14.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5172 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0014 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3714 - val_tp: 14.0000 - val_fp: 2.0000 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8750 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0013 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2880 - val_tp: 16.0000 - val_fp: 2.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 7.7657e-04 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1758 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 7.3722e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1225 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 5.5616e-04 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0569 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 4.5781e-04 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0408 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 198ms/step - loss: 0.5754 - tp: 130.0000 - fp: 20.0000 - tn: 141.0000 - fn: 29.0000 - accuracy: 0.8469 - precision: 0.8667 - recall: 0.8176 - auc: 0.9011 - val_loss: 0.6830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8333\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1038 - tp: 151.0000 - fp: 5.0000 - tn: 155.0000 - fn: 9.0000 - accuracy: 0.9563 - precision: 0.9679 - recall: 0.9438 - auc: 0.9920 - val_loss: 0.7369 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 20.0000 - val_accuracy: 0.3750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9771\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.0202 - tp: 159.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 3.0000 - accuracy: 0.9906 - precision: 1.0000 - recall: 0.9815 - auc: 0.9999 - val_loss: 0.7068 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0090 - tp: 164.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9939 - auc: 1.0000 - val_loss: 0.7585 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9412\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0059 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7437 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.0034 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7333 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0018 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7466 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0011 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7624 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0012 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6845 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 5.0595e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6913 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 34ms/step - loss: 5.8661e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6521 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 6.6380e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5635 - val_tp: 4.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 11.0000 - val_accuracy: 0.6562 - val_precision: 1.0000 - val_recall: 0.2667 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 8.9797e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4245 - val_tp: 9.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 7.0000 - val_accuracy: 0.7812 - val_precision: 1.0000 - val_recall: 0.5625 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 3.7522e-04 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2481 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.7857 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 3.1860e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2225 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8667 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 182ms/step - loss: 0.7422 - tp: 128.0000 - fp: 22.0000 - tn: 141.0000 - fn: 29.0000 - accuracy: 0.8406 - precision: 0.8533 - recall: 0.8153 - auc: 0.8982 - val_loss: 0.6641 - val_tp: 15.0000 - val_fp: 15.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0280 - tp: 160.0000 - fp: 1.0000 - tn: 157.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9938 - recall: 0.9877 - auc: 0.9996 - val_loss: 0.6687 - val_tp: 14.0000 - val_fp: 16.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4667 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0150 - tp: 163.0000 - fp: 1.0000 - tn: 155.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9939 - recall: 0.9939 - auc: 1.0000 - val_loss: 0.6607 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9961\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.0115 - tp: 155.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.6677 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 0.9921\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0037 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6512 - val_tp: 15.0000 - val_fp: 10.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 0.9843\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0041 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6529 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9941\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0024 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6463 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9804\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 8.2509e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5898 - val_tp: 18.0000 - val_fp: 12.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 0.9841\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 7.3704e-04 - tp: 171.0000 - fp: 0.0000e+00 - tn: 149.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5881 - val_tp: 16.0000 - val_fp: 12.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5714 - val_recall: 1.0000 - val_auc: 0.9609\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0010 - tp: 149.0000 - fp: 0.0000e+00 - tn: 171.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5761 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9725\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 3.0169e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5901 - val_tp: 15.0000 - val_fp: 15.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9745\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0011 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6945 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9727\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 3.1426e-04 - tp: 149.0000 - fp: 0.0000e+00 - tn: 171.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7104 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9805\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 4.3239e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5670 - val_tp: 19.0000 - val_fp: 12.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.6129 - val_recall: 1.0000 - val_auc: 0.9798\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 2.3290e-04 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7888 - val_tp: 16.0000 - val_fp: 14.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5333 - val_recall: 1.0000 - val_auc: 0.9766\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 6s 276ms/step - loss: 1.9573 - tp: 109.0000 - fp: 63.0000 - tn: 96.0000 - fn: 52.0000 - accuracy: 0.6406 - precision: 0.6337 - recall: 0.6770 - auc: 0.7146 - val_loss: 0.6869 - val_tp: 14.0000 - val_fp: 14.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.8512\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.1233 - tp: 144.0000 - fp: 2.0000 - tn: 158.0000 - fn: 16.0000 - accuracy: 0.9438 - precision: 0.9863 - recall: 0.9000 - auc: 0.9943 - val_loss: 0.7023 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9490\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0686 - tp: 157.0000 - fp: 3.0000 - tn: 155.0000 - fn: 5.0000 - accuracy: 0.9750 - precision: 0.9812 - recall: 0.9691 - auc: 0.9947 - val_loss: 0.6688 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0251 - tp: 157.0000 - fp: 1.0000 - tn: 161.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9996 - val_loss: 0.6694 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0218 - tp: 156.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.7419 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.0077 - tp: 160.0000 - fp: 1.0000 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 0.9969 - precision: 0.9938 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6750 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0058 - tp: 163.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9939 - auc: 1.0000 - val_loss: 0.7897 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.0029 - tp: 147.0000 - fp: 0.0000e+00 - tn: 173.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7641 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0032 - tp: 173.0000 - fp: 0.0000e+00 - tn: 147.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9317 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0040 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8300 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.0014 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9897 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0019 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8604 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0018 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9441 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0013 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9221 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.0019 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5544 - val_tp: 18.0000 - val_fp: 12.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 164ms/step - loss: 0.9823 - tp: 122.0000 - fp: 43.0000 - tn: 116.0000 - fn: 39.0000 - accuracy: 0.7437 - precision: 0.7394 - recall: 0.7578 - auc: 0.8002 - val_loss: 0.6885 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9414\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0476 - tp: 160.0000 - fp: 2.0000 - tn: 155.0000 - fn: 3.0000 - accuracy: 0.9844 - precision: 0.9877 - recall: 0.9816 - auc: 0.9978 - val_loss: 0.6857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0161 - tp: 151.0000 - fp: 1.0000 - tn: 167.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9934 - recall: 0.9934 - auc: 0.9999 - val_loss: 0.7031 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8706\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0124 - tp: 165.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9940 - auc: 1.0000 - val_loss: 0.7096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9588\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0094 - tp: 154.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9935 - auc: 1.0000 - val_loss: 0.6779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9821\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0022 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7090 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9883\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0014 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7153 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9824\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.0022 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7000 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0013 - tp: 174.0000 - fp: 0.0000e+00 - tn: 146.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6880 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0014 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6373 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 5.7578e-04 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6386 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 5.7542e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6095 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 1.0000 - val_recall: 0.1250 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 5.1908e-04 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5889 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 1.0000 - val_recall: 0.0625 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 3.9815e-04 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5047 - val_tp: 5.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 12.0000 - val_accuracy: 0.6250 - val_precision: 1.0000 - val_recall: 0.2941 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 4.9517e-04 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3003 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8125 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 165ms/step - loss: 0.7398 - tp: 132.0000 - fp: 34.0000 - tn: 124.0000 - fn: 30.0000 - accuracy: 0.8000 - precision: 0.7952 - recall: 0.8148 - auc: 0.8571 - val_loss: 0.6672 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 1.0000 - val_recall: 0.0625 - val_auc: 0.9238\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0891 - tp: 149.0000 - fp: 2.0000 - tn: 163.0000 - fn: 6.0000 - accuracy: 0.9750 - precision: 0.9868 - recall: 0.9613 - auc: 0.9907 - val_loss: 0.6984 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7510\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0434 - tp: 152.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 4.0000 - accuracy: 0.9875 - precision: 1.0000 - recall: 0.9744 - auc: 0.9950 - val_loss: 0.7670 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6863\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.0240 - tp: 162.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9878 - auc: 0.9995 - val_loss: 0.7189 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8941\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0234 - tp: 155.0000 - fp: 1.0000 - tn: 163.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9936 - auc: 0.9998 - val_loss: 0.7848 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9180\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0188 - tp: 161.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9938 - auc: 0.9986 - val_loss: 0.8594 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8039\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0113 - tp: 160.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9938 - auc: 1.0000 - val_loss: 0.8142 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8750\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0146 - tp: 153.0000 - fp: 1.0000 - tn: 164.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9935 - recall: 0.9871 - auc: 0.9999 - val_loss: 0.6245 - val_tp: 4.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 12.0000 - val_accuracy: 0.6250 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.9258\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0224 - tp: 167.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9882 - auc: 0.9998 - val_loss: 0.4740 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 4.0000 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.7647 - val_auc: 0.8510\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0136 - tp: 148.0000 - fp: 0.0000e+00 - tn: 171.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9933 - auc: 0.9998 - val_loss: 0.5285 - val_tp: 6.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 8.0000 - val_accuracy: 0.7500 - val_precision: 1.0000 - val_recall: 0.4286 - val_auc: 0.8869\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 44ms/step - loss: 0.0040 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4737 - val_tp: 9.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 7.0000 - val_accuracy: 0.7812 - val_precision: 1.0000 - val_recall: 0.5625 - val_auc: 0.9141\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 7.3749e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5513 - val_tp: 9.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.7500 - val_precision: 1.0000 - val_recall: 0.5294 - val_auc: 0.9216\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 4.0893e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3022 - val_tp: 8.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 5.0000 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.6154 - val_auc: 0.9352\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 8.7784e-04 - tp: 171.0000 - fp: 0.0000e+00 - tn: 149.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4185 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 4.0000 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.7333 - val_auc: 0.8980\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 2.5456e-04 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2401 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8667 - val_auc: 0.9451\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.3426 - tp: 146.0000 - fp: 13.0000 - tn: 145.0000 - fn: 16.0000 - accuracy: 0.9094 - precision: 0.9182 - recall: 0.9012 - auc: 0.9463 - val_loss: 0.5976 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9375 - val_auc: 0.9648\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0451 - tp: 157.0000 - fp: 3.0000 - tn: 158.0000 - fn: 2.0000 - accuracy: 0.9844 - precision: 0.9812 - recall: 0.9874 - auc: 0.9988 - val_loss: 0.5768 - val_tp: 10.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 5.0000 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.6667 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0023 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5436 - val_tp: 8.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 7.0000 - val_accuracy: 0.7812 - val_precision: 1.0000 - val_recall: 0.5333 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 9.5223e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5135 - val_tp: 9.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 6.0000 - val_accuracy: 0.8125 - val_precision: 1.0000 - val_recall: 0.6000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 2.6372e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4954 - val_tp: 6.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 9.0000 - val_accuracy: 0.7188 - val_precision: 1.0000 - val_recall: 0.4000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 2.9566e-04 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4101 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8125 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 1.5421e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3466 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 4.0000 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.7647 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.9212e-04 - tp: 170.0000 - fp: 0.0000e+00 - tn: 150.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2368 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 4.0000 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.7778 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 2.3268e-04 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1691 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8667 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 1.0663e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1434 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8889 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 9.4588e-05 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0608 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 1.1293e-04 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0700 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 3.0336e-04 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0375 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 1.2046e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0321 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 1.1498e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0183 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 5s 263ms/step - loss: 1.9266 - tp: 118.0000 - fp: 51.0000 - tn: 108.0000 - fn: 43.0000 - accuracy: 0.7063 - precision: 0.6982 - recall: 0.7329 - auc: 0.7564 - val_loss: 0.6658 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9882\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.0847 - tp: 153.0000 - fp: 1.0000 - tn: 159.0000 - fn: 7.0000 - accuracy: 0.9750 - precision: 0.9935 - recall: 0.9563 - auc: 0.9933 - val_loss: 0.6695 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0171 - tp: 156.0000 - fp: 1.0000 - tn: 162.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9936 - auc: 0.9999 - val_loss: 0.6917 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0141 - tp: 157.0000 - fp: 1.0000 - tn: 161.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.6936 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9922\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0153 - tp: 162.0000 - fp: 2.0000 - tn: 155.0000 - fn: 1.0000 - accuracy: 0.9906 - precision: 0.9878 - recall: 0.9939 - auc: 0.9998 - val_loss: 0.6704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0055 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7087 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0028 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7444 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0048 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5829 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 1.0000 - val_recall: 0.1250 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0026 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6129 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0021 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6519 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0023 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_tp: 7.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 10.0000 - val_accuracy: 0.6875 - val_precision: 1.0000 - val_recall: 0.4118 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0016 - tp: 148.0000 - fp: 0.0000e+00 - tn: 172.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6040 - val_tp: 5.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 13.0000 - val_accuracy: 0.5938 - val_precision: 1.0000 - val_recall: 0.2778 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 9.4881e-04 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4223 - val_tp: 8.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 8.0000 - val_accuracy: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0011 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4754 - val_tp: 8.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.7188 - val_precision: 1.0000 - val_recall: 0.4706 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.0011 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3877 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8421 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 162ms/step - loss: 1.3383 - tp: 104.0000 - fp: 55.0000 - tn: 105.0000 - fn: 56.0000 - accuracy: 0.6531 - precision: 0.6541 - recall: 0.6500 - auc: 0.6836 - val_loss: 0.6794 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1230 - tp: 152.0000 - fp: 1.0000 - tn: 156.0000 - fn: 11.0000 - accuracy: 0.9625 - precision: 0.9935 - recall: 0.9325 - auc: 0.9901 - val_loss: 0.6874 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0317 - tp: 154.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 3.0000 - accuracy: 0.9906 - precision: 1.0000 - recall: 0.9809 - auc: 0.9996 - val_loss: 0.7546 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.0184 - tp: 159.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9937 - auc: 0.9998 - val_loss: 0.7328 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0067 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7642 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0048 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9833 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0025 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8300 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.0012 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0218 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 8.1004e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2169 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0011 - tp: 171.0000 - fp: 0.0000e+00 - tn: 149.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3328 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 8.4084e-04 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3456 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 4.0542e-04 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0305 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 3.6735e-04 - tp: 150.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9609 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 3.1974e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0851 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.7412e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7826 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 181ms/step - loss: 0.3095 - tp: 149.0000 - fp: 13.0000 - tn: 145.0000 - fn: 13.0000 - accuracy: 0.9187 - precision: 0.9198 - recall: 0.9198 - auc: 0.9509 - val_loss: 0.5388 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0776 - tp: 152.0000 - fp: 2.0000 - tn: 161.0000 - fn: 5.0000 - accuracy: 0.9781 - precision: 0.9870 - recall: 0.9682 - auc: 0.9927 - val_loss: 0.5077 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0440 - tp: 156.0000 - fp: 1.0000 - tn: 160.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9936 - recall: 0.9811 - auc: 0.9974 - val_loss: 0.5201 - val_tp: 10.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 6.0000 - val_accuracy: 0.8125 - val_precision: 1.0000 - val_recall: 0.6250 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.0246 - tp: 161.0000 - fp: 1.0000 - tn: 154.0000 - fn: 4.0000 - accuracy: 0.9844 - precision: 0.9938 - recall: 0.9758 - auc: 0.9997 - val_loss: 0.5339 - val_tp: 15.0000 - val_fp: 8.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.6522 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0082 - tp: 154.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9935 - auc: 1.0000 - val_loss: 0.4925 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0110 - tp: 157.0000 - fp: 1.0000 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 0.9969 - precision: 0.9937 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4863 - val_tp: 15.0000 - val_fp: 15.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0099 - tp: 168.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9941 - auc: 1.0000 - val_loss: 0.3679 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0097 - tp: 156.0000 - fp: 1.0000 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 0.9969 - precision: 0.9936 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4314 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 5.0000 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.7222 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0017 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2127 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 1.3678e-04 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1658 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0064 - tp: 157.0000 - fp: 1.0000 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 0.9969 - precision: 0.9937 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1255 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0024 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0360 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0187 - tp: 166.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9940 - auc: 0.9993 - val_loss: 0.0436 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0245 - tp: 160.0000 - fp: 1.0000 - tn: 158.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9938 - recall: 0.9938 - auc: 0.9998 - val_loss: 0.0225 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0260 - tp: 145.0000 - fp: 1.0000 - tn: 173.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9932 - recall: 0.9932 - auc: 0.9969 - val_loss: 2.6005e-04 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 187ms/step - loss: 0.8637 - tp: 125.0000 - fp: 40.0000 - tn: 118.0000 - fn: 37.0000 - accuracy: 0.7594 - precision: 0.7576 - recall: 0.7716 - auc: 0.8409 - val_loss: 0.6841 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0907 - tp: 158.0000 - fp: 1.0000 - tn: 154.0000 - fn: 7.0000 - accuracy: 0.9750 - precision: 0.9937 - recall: 0.9576 - auc: 0.9966 - val_loss: 0.6807 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9961\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0478 - tp: 151.0000 - fp: 3.0000 - tn: 163.0000 - fn: 3.0000 - accuracy: 0.9812 - precision: 0.9805 - recall: 0.9805 - auc: 0.9983 - val_loss: 0.6802 - val_tp: 4.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 13.0000 - val_accuracy: 0.5938 - val_precision: 1.0000 - val_recall: 0.2353 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.0127 - tp: 163.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9939 - auc: 1.0000 - val_loss: 0.6724 - val_tp: 16.0000 - val_fp: 2.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0050 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6649 - val_tp: 18.0000 - val_fp: 7.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.7200 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0066 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6720 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0028 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6473 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0025 - tp: 150.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6144 - val_tp: 14.0000 - val_fp: 9.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7188 - val_precision: 0.6087 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 9.4278e-04 - tp: 171.0000 - fp: 0.0000e+00 - tn: 149.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5552 - val_tp: 17.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6296 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0010 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5319 - val_tp: 15.0000 - val_fp: 12.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5556 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0012 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4755 - val_tp: 15.0000 - val_fp: 10.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 3.8777e-04 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3666 - val_tp: 17.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.7727 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 5.2592e-04 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3616 - val_tp: 17.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7391 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 5.1343e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3483 - val_tp: 19.0000 - val_fp: 6.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7600 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 1.7150e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3354 - val_tp: 17.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7391 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 5s 271ms/step - loss: 1.2966 - tp: 114.0000 - fp: 42.0000 - tn: 120.0000 - fn: 44.0000 - accuracy: 0.7312 - precision: 0.7308 - recall: 0.7215 - auc: 0.8136 - val_loss: 0.6352 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.1150 - tp: 155.0000 - fp: 8.0000 - tn: 152.0000 - fn: 5.0000 - accuracy: 0.9594 - precision: 0.9509 - recall: 0.9688 - auc: 0.9901 - val_loss: 0.5797 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.0482 - tp: 156.0000 - fp: 3.0000 - tn: 158.0000 - fn: 3.0000 - accuracy: 0.9812 - precision: 0.9811 - recall: 0.9811 - auc: 0.9986 - val_loss: 0.5560 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 64ms/step - loss: 0.0310 - tp: 150.0000 - fp: 1.0000 - tn: 167.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9934 - recall: 0.9868 - auc: 0.9994 - val_loss: 0.5213 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0154 - tp: 157.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9874 - auc: 0.9999 - val_loss: 0.4781 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0138 - tp: 166.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9940 - auc: 1.0000 - val_loss: 0.3931 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.0067 - tp: 157.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.3189 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0037 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2751 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.0033 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2093 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0019 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1824 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0015 - tp: 170.0000 - fp: 0.0000e+00 - tn: 150.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0793 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.0022 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0931 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 8.4670e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0403 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.0080 - tp: 160.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9938 - auc: 1.0000 - val_loss: 0.0269 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0017 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0093 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 166ms/step - loss: 1.4804 - tp: 103.0000 - fp: 64.0000 - tn: 94.0000 - fn: 59.0000 - accuracy: 0.6156 - precision: 0.6168 - recall: 0.6358 - auc: 0.6262 - val_loss: 0.6966 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9333\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.1828 - tp: 146.0000 - fp: 7.0000 - tn: 156.0000 - fn: 11.0000 - accuracy: 0.9438 - precision: 0.9542 - recall: 0.9299 - auc: 0.9867 - val_loss: 0.6815 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0795 - tp: 155.0000 - fp: 2.0000 - tn: 157.0000 - fn: 6.0000 - accuracy: 0.9750 - precision: 0.9873 - recall: 0.9627 - auc: 0.9944 - val_loss: 0.7043 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0306 - tp: 157.0000 - fp: 1.0000 - tn: 161.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9998 - val_loss: 0.7128 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0190 - tp: 168.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9941 - auc: 0.9999 - val_loss: 0.5450 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 13.0000 - val_accuracy: 0.5938 - val_precision: 1.0000 - val_recall: 0.0714 - val_auc: 1.0000\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0081 - tp: 155.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9936 - auc: 1.0000 - val_loss: 0.4497 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0031 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3870 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8667 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.0025 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3267 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0019 - tp: 151.0000 - fp: 0.0000e+00 - tn: 169.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2317 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0015 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1541 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0011 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1209 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0014 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0812 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0013 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0564 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 5.5497e-04 - tp: 151.0000 - fp: 0.0000e+00 - tn: 169.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0364 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 6.2754e-04 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0237 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 164ms/step - loss: 0.4281 - tp: 138.0000 - fp: 29.0000 - tn: 131.0000 - fn: 22.0000 - accuracy: 0.8406 - precision: 0.8263 - recall: 0.8625 - auc: 0.9237 - val_loss: 0.6003 - val_tp: 8.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 7.0000 - val_accuracy: 0.7812 - val_precision: 1.0000 - val_recall: 0.5333 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0660 - tp: 154.0000 - fp: 1.0000 - tn: 159.0000 - fn: 6.0000 - accuracy: 0.9781 - precision: 0.9935 - recall: 0.9625 - auc: 0.9953 - val_loss: 0.6223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0340 - tp: 159.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 3.0000 - accuracy: 0.9906 - precision: 1.0000 - recall: 0.9815 - auc: 0.9993 - val_loss: 0.6109 - val_tp: 9.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 7.0000 - val_accuracy: 0.7812 - val_precision: 1.0000 - val_recall: 0.5625 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.0300 - tp: 156.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 3.0000 - accuracy: 0.9906 - precision: 1.0000 - recall: 0.9811 - auc: 0.9997 - val_loss: 0.5857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0267 - tp: 149.0000 - fp: 1.0000 - tn: 167.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9933 - recall: 0.9803 - auc: 0.9995 - val_loss: 0.5111 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8125 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0107 - tp: 164.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9939 - auc: 1.0000 - val_loss: 0.4735 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0046 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3701 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0022 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2776 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0014 - tp: 170.0000 - fp: 0.0000e+00 - tn: 150.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2035 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0014 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1876 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0011 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1418 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 6.0646e-04 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1076 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 6.8490e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1389 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.0022 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1253 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0010 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0778 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 0.2346 - tp: 144.0000 - fp: 14.0000 - tn: 146.0000 - fn: 16.0000 - accuracy: 0.9062 - precision: 0.9114 - recall: 0.9000 - auc: 0.9720 - val_loss: 0.6774 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.0032 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6861 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0072 - tp: 157.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.6720 - val_tp: 7.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 9.0000 - val_accuracy: 0.7188 - val_precision: 1.0000 - val_recall: 0.4375 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 6.4379e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6809 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 3.3019e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6581 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 6.2233e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6508 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.6291e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6254 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 5.0000 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.6875 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 1.3543e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6107 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8235 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.6125e-04 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5863 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 1.7135e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5514 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 6.8285e-05 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4849 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 1.6552e-04 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4043 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 6.9605e-05 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3435 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 1.3833e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2741 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 1.2864e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2524 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 5s 266ms/step - loss: 1.5080 - tp: 127.0000 - fp: 47.0000 - tn: 110.0000 - fn: 36.0000 - accuracy: 0.7406 - precision: 0.7299 - recall: 0.7791 - auc: 0.8146 - val_loss: 0.5757 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.2194 - tp: 142.0000 - fp: 4.0000 - tn: 160.0000 - fn: 14.0000 - accuracy: 0.9438 - precision: 0.9726 - recall: 0.9103 - auc: 0.9752 - val_loss: 0.4610 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0400 - tp: 163.0000 - fp: 1.0000 - tn: 153.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9939 - recall: 0.9819 - auc: 0.9964 - val_loss: 0.4580 - val_tp: 16.0000 - val_fp: 5.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.7619 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0108 - tp: 155.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9936 - auc: 1.0000 - val_loss: 0.3681 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0090 - tp: 158.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.3472 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0112 - tp: 156.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9936 - auc: 0.9999 - val_loss: 0.3282 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0068 - tp: 163.0000 - fp: 1.0000 - tn: 155.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9939 - recall: 0.9939 - auc: 1.0000 - val_loss: 0.2366 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0051 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3587 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.0060 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2275 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 5.2023e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3456 - val_tp: 14.0000 - val_fp: 2.0000 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8750 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 7.1450e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2885 - val_tp: 16.0000 - val_fp: 2.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 4.3426e-04 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2709 - val_tp: 16.0000 - val_fp: 1.0000 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9412 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 4.9249e-04 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4461 - val_tp: 14.0000 - val_fp: 12.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5385 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 6.4014e-04 - tp: 149.0000 - fp: 0.0000e+00 - tn: 171.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3107 - val_tp: 19.0000 - val_fp: 8.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.7037 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 3.6612e-04 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3605 - val_tp: 15.0000 - val_fp: 10.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6875 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 0.4674 - tp: 139.0000 - fp: 20.0000 - tn: 139.0000 - fn: 22.0000 - accuracy: 0.8687 - precision: 0.8742 - recall: 0.8634 - auc: 0.9200 - val_loss: 0.6766 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.0421 - tp: 156.0000 - fp: 1.0000 - tn: 161.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9936 - recall: 0.9873 - auc: 0.9960 - val_loss: 0.7059 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0056 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6989 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9412\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.0037 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7765 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9844\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0020 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7992 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9922\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0013 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8805 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9961\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 1.6914e-04 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8726 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 4.8979e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8740 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 3.2157e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0496 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 8.7277e-05 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0097 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 3.2724e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7946 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 1.5942e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5748 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0010 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9223 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 3.0737e-04 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4769 - val_tp: 16.0000 - val_fp: 13.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5517 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 5.9174e-05 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2901 - val_tp: 18.0000 - val_fp: 4.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8182 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.5966 - tp: 131.0000 - fp: 30.0000 - tn: 126.0000 - fn: 33.0000 - accuracy: 0.8031 - precision: 0.8137 - recall: 0.7988 - auc: 0.8955 - val_loss: 0.7008 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0993 - tp: 149.0000 - fp: 2.0000 - tn: 162.0000 - fn: 7.0000 - accuracy: 0.9719 - precision: 0.9868 - recall: 0.9551 - auc: 0.9899 - val_loss: 0.6970 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.2353\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 66ms/step - loss: 0.0386 - tp: 150.0000 - fp: 1.0000 - tn: 166.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9934 - recall: 0.9804 - auc: 0.9991 - val_loss: 0.6966 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.1471\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.0345 - tp: 168.0000 - fp: 1.0000 - tn: 149.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9941 - recall: 0.9882 - auc: 0.9985 - val_loss: 0.7165 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.1641\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0181 - tp: 146.0000 - fp: 0.0000e+00 - tn: 171.0000 - fn: 3.0000 - accuracy: 0.9906 - precision: 1.0000 - recall: 0.9799 - auc: 1.0000 - val_loss: 0.6935 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.0873\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0184 - tp: 171.0000 - fp: 1.0000 - tn: 146.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9942 - recall: 0.9884 - auc: 0.9998 - val_loss: 0.7022 - val_tp: 8.0000 - val_fp: 16.0000 - val_tn: 2.0000 - val_fn: 6.0000 - val_accuracy: 0.3125 - val_precision: 0.3333 - val_recall: 0.5714 - val_auc: 0.1984\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0081 - tp: 158.0000 - fp: 1.0000 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 0.9969 - precision: 0.9937 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7192 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.1523\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0059 - tp: 167.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9940 - auc: 1.0000 - val_loss: 0.7341 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.3118\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0034 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7055 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.2451\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.0012 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7059 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.3510\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0018 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7082 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.6059\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 9.6377e-04 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6709 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9098\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 7.2679e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6418 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9765\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 6.1555e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6075 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5185 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 6.2375e-04 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5387 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.7783 - tp: 128.0000 - fp: 26.0000 - tn: 135.0000 - fn: 31.0000 - accuracy: 0.8219 - precision: 0.8312 - recall: 0.8050 - auc: 0.8706 - val_loss: 0.6572 - val_tp: 17.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5667 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0615 - tp: 159.0000 - fp: 2.0000 - tn: 154.0000 - fn: 5.0000 - accuracy: 0.9781 - precision: 0.9876 - recall: 0.9695 - auc: 0.9978 - val_loss: 0.6752 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9922\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0213 - tp: 154.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9872 - auc: 1.0000 - val_loss: 0.7178 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9353\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.0091 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7459 - val_tp: 13.0000 - val_fp: 19.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4062 - val_precision: 0.4062 - val_recall: 1.0000 - val_auc: 0.9150\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0049 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7544 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 0.9643\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0019 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6551 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0026 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6787 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 9.7981e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6006 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 6.8907e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5622 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.0012 - tp: 171.0000 - fp: 0.0000e+00 - tn: 149.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4917 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 6.6633e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4764 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 4.6669e-04 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3888 - val_tp: 16.0000 - val_fp: 11.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6562 - val_precision: 0.5926 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 7.7257e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4763 - val_tp: 15.0000 - val_fp: 15.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 5.0415e-04 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2255 - val_tp: 15.0000 - val_fp: 1.0000 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 2.7320e-04 - tp: 150.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1393 - val_tp: 19.0000 - val_fp: 2.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9048 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 5s 251ms/step - loss: 0.9628 - tp: 126.0000 - fp: 36.0000 - tn: 124.0000 - fn: 34.0000 - accuracy: 0.7812 - precision: 0.7778 - recall: 0.7875 - auc: 0.8249 - val_loss: 0.6576 - val_tp: 4.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 9.0000 - val_accuracy: 0.7188 - val_precision: 1.0000 - val_recall: 0.3077 - val_auc: 0.9879\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.1124 - tp: 152.0000 - fp: 2.0000 - tn: 159.0000 - fn: 7.0000 - accuracy: 0.9719 - precision: 0.9870 - recall: 0.9560 - auc: 0.9899 - val_loss: 0.6654 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9882\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0893 - tp: 157.0000 - fp: 3.0000 - tn: 155.0000 - fn: 5.0000 - accuracy: 0.9750 - precision: 0.9812 - recall: 0.9691 - auc: 0.9961 - val_loss: 0.6935 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9824\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0083 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9765\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0114 - tp: 156.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.6644 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0071 - tp: 160.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9938 - auc: 1.0000 - val_loss: 0.6357 - val_tp: 17.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.6800 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0054 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6190 - val_tp: 16.0000 - val_fp: 14.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5333 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0035 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6137 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0023 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6299 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0020 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4488 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.0026 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5171 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 8.2963e-04 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4508 - val_tp: 13.0000 - val_fp: 9.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7188 - val_precision: 0.5909 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0015 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4819 - val_tp: 15.0000 - val_fp: 12.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5556 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0015 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2958 - val_tp: 16.0000 - val_fp: 4.0000 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 4.4971e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2931 - val_tp: 15.0000 - val_fp: 4.0000 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.7895 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 167ms/step - loss: 0.8903 - tp: 112.0000 - fp: 40.0000 - tn: 118.0000 - fn: 50.0000 - accuracy: 0.7188 - precision: 0.7368 - recall: 0.6914 - auc: 0.7884 - val_loss: 0.6816 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.9484\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0708 - tp: 152.0000 - fp: 2.0000 - tn: 164.0000 - fn: 2.0000 - accuracy: 0.9875 - precision: 0.9870 - recall: 0.9870 - auc: 0.9941 - val_loss: 0.6925 - val_tp: 13.0000 - val_fp: 19.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4062 - val_precision: 0.4062 - val_recall: 1.0000 - val_auc: 0.9919\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0299 - tp: 164.0000 - fp: 1.0000 - tn: 151.0000 - fn: 4.0000 - accuracy: 0.9844 - precision: 0.9939 - recall: 0.9762 - auc: 0.9997 - val_loss: 0.6270 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0139 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6538 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0091 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6579 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0093 - tp: 163.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9939 - auc: 1.0000 - val_loss: 0.8340 - val_tp: 13.0000 - val_fp: 19.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4062 - val_precision: 0.4062 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0032 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5589 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0027 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4864 - val_tp: 16.0000 - val_fp: 14.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5333 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0014 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4702 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5185 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0013 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3460 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7273 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 6.3305e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2648 - val_tp: 15.0000 - val_fp: 2.0000 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 7.4388e-04 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1974 - val_tp: 15.0000 - val_fp: 1.0000 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 6.2454e-04 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1226 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 6.1192e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1082 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 5.4677e-04 - tp: 171.0000 - fp: 0.0000e+00 - tn: 149.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0590 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 178ms/step - loss: 0.4667 - tp: 133.0000 - fp: 29.0000 - tn: 132.0000 - fn: 26.0000 - accuracy: 0.8281 - precision: 0.8210 - recall: 0.8365 - auc: 0.9170 - val_loss: 0.6851 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9765\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.1065 - tp: 155.0000 - fp: 6.0000 - tn: 152.0000 - fn: 7.0000 - accuracy: 0.9594 - precision: 0.9627 - recall: 0.9568 - auc: 0.9913 - val_loss: 0.7889 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9373\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1224 - tp: 160.0000 - fp: 1.0000 - tn: 155.0000 - fn: 4.0000 - accuracy: 0.9844 - precision: 0.9938 - recall: 0.9756 - auc: 0.9877 - val_loss: 0.6915 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8413\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.0632 - tp: 150.0000 - fp: 1.0000 - tn: 165.0000 - fn: 4.0000 - accuracy: 0.9844 - precision: 0.9934 - recall: 0.9740 - auc: 0.9948 - val_loss: 0.7283 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9059\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0276 - tp: 163.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9879 - auc: 0.9993 - val_loss: 0.8185 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9529\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0194 - tp: 164.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9880 - auc: 0.9997 - val_loss: 0.7734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9266\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0092 - tp: 148.0000 - fp: 0.0000e+00 - tn: 171.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9933 - auc: 1.0000 - val_loss: 0.9589 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9294\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0091 - tp: 162.0000 - fp: 1.0000 - tn: 156.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9939 - recall: 0.9939 - auc: 1.0000 - val_loss: 1.0641 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9569\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0046 - tp: 162.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9939 - auc: 1.0000 - val_loss: 0.9703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9609\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0018 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9717 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0022 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9804\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0012 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0636 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9902\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0026 - tp: 172.0000 - fp: 0.0000e+00 - tn: 148.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1006 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9824\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 7.5034e-04 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7110 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 12.0000 - val_accuracy: 0.6250 - val_precision: 1.0000 - val_recall: 0.1429 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 5.2189e-04 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5273 - val_tp: 3.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 10.0000 - val_accuracy: 0.6875 - val_precision: 1.0000 - val_recall: 0.2308 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.2261 - tp: 142.0000 - fp: 8.0000 - tn: 154.0000 - fn: 16.0000 - accuracy: 0.9250 - precision: 0.9467 - recall: 0.8987 - auc: 0.9695 - val_loss: 0.6537 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9492\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0238 - tp: 159.0000 - fp: 1.0000 - tn: 157.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9937 - recall: 0.9815 - auc: 0.9998 - val_loss: 0.7161 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.6641\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0082 - tp: 157.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.7069 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.3588\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.0064 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7026 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.3631\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0020 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7954 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.4353\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 2s 88ms/step - loss: 8.7820e-04 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8007 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.6431\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 8.1866e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7367 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.6333\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0012 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9846 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.7392\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 5.2788e-04 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8436 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7695\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 3.9550e-04 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9116 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.8926\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 3.5987e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8582 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.8651\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 2.0916e-04 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9279 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.8555\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 5.6776e-04 - tp: 151.0000 - fp: 0.0000e+00 - tn: 169.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8950 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.9048\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.8241e-04 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0626 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9141\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 1.8637e-04 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9011 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9098\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 5s 275ms/step - loss: 1.7417 - tp: 112.0000 - fp: 55.0000 - tn: 105.0000 - fn: 48.0000 - accuracy: 0.6781 - precision: 0.6707 - recall: 0.7000 - auc: 0.7483 - val_loss: 0.6719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9688\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0983 - tp: 150.0000 - fp: 3.0000 - tn: 157.0000 - fn: 10.0000 - accuracy: 0.9594 - precision: 0.9804 - recall: 0.9375 - auc: 0.9929 - val_loss: 0.6543 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.9802\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0074 - tp: 158.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.6803 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9882\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.0137 - tp: 158.0000 - fp: 1.0000 - tn: 160.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9998 - val_loss: 0.6712 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9922\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0055 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6275 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0215 - tp: 168.0000 - fp: 1.0000 - tn: 149.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9941 - recall: 0.9882 - auc: 0.9998 - val_loss: 0.7730 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9882\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0104 - tp: 154.0000 - fp: 1.0000 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 0.9969 - precision: 0.9935 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6821 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9725\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 0.0026 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6135 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9922\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0020 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5065 - val_tp: 16.0000 - val_fp: 9.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7188 - val_precision: 0.6400 - val_recall: 1.0000 - val_auc: 0.9922\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0013 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6152 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9843\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 3.9873e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4571 - val_tp: 18.0000 - val_fp: 12.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0032 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5829 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0012 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4690 - val_tp: 16.0000 - val_fp: 7.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.6957 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 5.1097e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3035 - val_tp: 17.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7391 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 4.2698e-04 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2102 - val_tp: 16.0000 - val_fp: 5.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.7619 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 188ms/step - loss: 0.5749 - tp: 129.0000 - fp: 29.0000 - tn: 133.0000 - fn: 29.0000 - accuracy: 0.8188 - precision: 0.8165 - recall: 0.8165 - auc: 0.8951 - val_loss: 0.6946 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 12.0000 - val_fn: 14.0000 - val_accuracy: 0.5000 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.5754\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0268 - tp: 161.0000 - fp: 2.0000 - tn: 155.0000 - fn: 2.0000 - accuracy: 0.9875 - precision: 0.9877 - recall: 0.9877 - auc: 0.9994 - val_loss: 0.7022 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9608\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0171 - tp: 161.0000 - fp: 1.0000 - tn: 156.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9938 - recall: 0.9877 - auc: 0.9998 - val_loss: 0.7871 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 0.8571\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0071 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9053 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9157\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.0134 - tp: 159.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.9906 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9219\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 33ms/step - loss: 3.4126e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0503 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9043\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 4.0693e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1290 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9059\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 3.6650e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.5192 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 0.9087\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 2.1389e-04 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2783 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.9841\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 1.4031e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2627 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 0.9919\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 1.2109e-04 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.9024 - val_tp: 12.0000 - val_fp: 20.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 2.2383e-04 - tp: 146.0000 - fp: 0.0000e+00 - tn: 174.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6882 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 1.2827e-04 - tp: 170.0000 - fp: 0.0000e+00 - tn: 150.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3288 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 9.3000e-05 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2002 - val_tp: 13.0000 - val_fp: 16.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4483 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 1.5513e-04 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7976 - val_tp: 14.0000 - val_fp: 15.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.4828 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.9387 - tp: 118.0000 - fp: 40.0000 - tn: 122.0000 - fn: 40.0000 - accuracy: 0.7500 - precision: 0.7468 - recall: 0.7468 - auc: 0.8302 - val_loss: 0.6467 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0956 - tp: 149.0000 - fp: 2.0000 - tn: 162.0000 - fn: 7.0000 - accuracy: 0.9719 - precision: 0.9868 - recall: 0.9551 - auc: 0.9876 - val_loss: 0.6078 - val_tp: 16.0000 - val_fp: 14.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5333 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0676 - tp: 151.0000 - fp: 1.0000 - tn: 163.0000 - fn: 5.0000 - accuracy: 0.9812 - precision: 0.9934 - recall: 0.9679 - auc: 0.9942 - val_loss: 0.6077 - val_tp: 15.0000 - val_fp: 9.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7188 - val_precision: 0.6250 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.0393 - tp: 162.0000 - fp: 1.0000 - tn: 154.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9939 - recall: 0.9818 - auc: 0.9983 - val_loss: 0.5815 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0288 - tp: 161.0000 - fp: 2.0000 - tn: 154.0000 - fn: 3.0000 - accuracy: 0.9844 - precision: 0.9877 - recall: 0.9817 - auc: 0.9996 - val_loss: 0.5733 - val_tp: 18.0000 - val_fp: 8.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.6923 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.0378 - tp: 155.0000 - fp: 1.0000 - tn: 161.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9936 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.5596 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8824 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.0070 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5153 - val_tp: 16.0000 - val_fp: 3.0000 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8421 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0120 - tp: 157.0000 - fp: 1.0000 - tn: 161.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5174 - val_tp: 10.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 5.0000 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.6667 - val_auc: 0.9725\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0125 - tp: 149.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9933 - auc: 1.0000 - val_loss: 0.4510 - val_tp: 17.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8095 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0064 - tp: 173.0000 - fp: 0.0000e+00 - tn: 147.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4039 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8889 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0030 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3495 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8667 - val_auc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0016 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2698 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9412 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0037 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2216 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9375 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 9.5818e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1538 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8889 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0010 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1221 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      " 1/20 [>.............................] - ETA: 37s - loss: 0.8682 - tp: 6.0000 - fp: 8.0000 - tn: 2.0000 - fn: 0.0000e+00 - accuracy: 0.5000 - precision: 0.4286 - recall: 1.0000 - auc: 0.6750WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.236949). Check your callbacks.\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 0.7891 - tp: 134.0000 - fp: 30.0000 - tn: 126.0000 - fn: 30.0000 - accuracy: 0.8125 - precision: 0.8171 - recall: 0.8171 - auc: 0.8666 - val_loss: 0.6877 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.0588 - val_auc: 0.8824\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0300 - tp: 145.0000 - fp: 2.0000 - tn: 169.0000 - fn: 4.0000 - accuracy: 0.9812 - precision: 0.9864 - recall: 0.9732 - auc: 0.9996 - val_loss: 0.7418 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7500\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0121 - tp: 172.0000 - fp: 0.0000e+00 - tn: 146.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9885 - auc: 1.0000 - val_loss: 0.7543 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9683\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.0088 - tp: 148.0000 - fp: 0.0000e+00 - tn: 171.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9933 - auc: 1.0000 - val_loss: 0.7030 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0030 - tp: 170.0000 - fp: 0.0000e+00 - tn: 150.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7842 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0022 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7291 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 8.0239e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 7.3938e-04 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7238 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 5.9613e-04 - tp: 151.0000 - fp: 0.0000e+00 - tn: 169.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6515 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 2.3330e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5864 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 4.5644e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5432 - val_tp: 3.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 13.0000 - val_accuracy: 0.5938 - val_precision: 1.0000 - val_recall: 0.1875 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 4.2633e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3927 - val_tp: 10.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 6.0000 - val_accuracy: 0.8125 - val_precision: 1.0000 - val_recall: 0.6250 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.3531e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2701 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8667 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 2.5978e-04 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1869 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.5581e-04 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1407 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 5s 257ms/step - loss: 2.6782 - tp: 92.0000 - fp: 56.0000 - tn: 106.0000 - fn: 66.0000 - accuracy: 0.6187 - precision: 0.6216 - recall: 0.5823 - auc: 0.6650 - val_loss: 0.6446 - val_tp: 16.0000 - val_fp: 2.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.2447 - tp: 155.0000 - fp: 12.0000 - tn: 146.0000 - fn: 7.0000 - accuracy: 0.9406 - precision: 0.9281 - recall: 0.9568 - auc: 0.9761 - val_loss: 0.6442 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.0329 - tp: 153.0000 - fp: 1.0000 - tn: 162.0000 - fn: 4.0000 - accuracy: 0.9844 - precision: 0.9935 - recall: 0.9745 - auc: 0.9995 - val_loss: 0.6220 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0178 - tp: 153.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9935 - auc: 0.9999 - val_loss: 0.6131 - val_tp: 10.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 5.0000 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.6667 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0072 - tp: 160.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9938 - auc: 1.0000 - val_loss: 0.5896 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8462 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0062 - tp: 167.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9940 - auc: 1.0000 - val_loss: 0.5455 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0087 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5385 - val_tp: 14.0000 - val_fp: 2.0000 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8750 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0028 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4569 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0029 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3894 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0060 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4847 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0030 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3429 - val_tp: 17.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.7727 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0015 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2321 - val_tp: 18.0000 - val_fp: 2.0000 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 0.0025 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2750 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0015 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1771 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0048 - tp: 162.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9939 - auc: 1.0000 - val_loss: 0.2028 - val_tp: 14.0000 - val_fp: 2.0000 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8750 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 166ms/step - loss: 1.2148 - tp: 99.0000 - fp: 49.0000 - tn: 116.0000 - fn: 56.0000 - accuracy: 0.6719 - precision: 0.6689 - recall: 0.6387 - auc: 0.7035 - val_loss: 0.6634 - val_tp: 14.0000 - val_fp: 1.0000 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9333 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.1056 - tp: 158.0000 - fp: 4.0000 - tn: 151.0000 - fn: 7.0000 - accuracy: 0.9656 - precision: 0.9753 - recall: 0.9576 - auc: 0.9914 - val_loss: 0.6443 - val_tp: 17.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7391 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0392 - tp: 158.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9875 - auc: 0.9983 - val_loss: 0.6406 - val_tp: 16.0000 - val_fp: 2.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.0238 - tp: 160.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9938 - auc: 0.9997 - val_loss: 0.6226 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.0047 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5755 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0039 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5250 - val_tp: 16.0000 - val_fp: 4.0000 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0019 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4249 - val_tp: 18.0000 - val_fp: 5.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.7826 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0013 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3238 - val_tp: 19.0000 - val_fp: 2.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9048 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0018 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3729 - val_tp: 17.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7391 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0020 - tp: 150.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2310 - val_tp: 17.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8095 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 7.6443e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2008 - val_tp: 17.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8947 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 6.1680e-04 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1272 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 8.3120e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1327 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 4.9700e-04 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0821 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 3.6022e-04 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0368 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 185ms/step - loss: 1.1129 - tp: 115.0000 - fp: 45.0000 - tn: 116.0000 - fn: 44.0000 - accuracy: 0.7219 - precision: 0.7188 - recall: 0.7233 - auc: 0.7495 - val_loss: 0.6027 - val_tp: 16.0000 - val_fp: 7.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.6957 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1305 - tp: 148.0000 - fp: 2.0000 - tn: 160.0000 - fn: 10.0000 - accuracy: 0.9625 - precision: 0.9867 - recall: 0.9367 - auc: 0.9902 - val_loss: 0.5590 - val_tp: 17.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5484 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0511 - tp: 150.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 4.0000 - accuracy: 0.9875 - precision: 1.0000 - recall: 0.9740 - auc: 0.9991 - val_loss: 0.5541 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.0693 - tp: 171.0000 - fp: 3.0000 - tn: 142.0000 - fn: 4.0000 - accuracy: 0.9781 - precision: 0.9828 - recall: 0.9771 - auc: 0.9973 - val_loss: 0.5919 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0392 - tp: 150.0000 - fp: 2.0000 - tn: 165.0000 - fn: 3.0000 - accuracy: 0.9844 - precision: 0.9868 - recall: 0.9804 - auc: 0.9985 - val_loss: 0.6096 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.0189 - tp: 147.0000 - fp: 0.0000e+00 - tn: 172.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9932 - auc: 1.0000 - val_loss: 0.7082 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0249 - tp: 170.0000 - fp: 0.0000e+00 - tn: 148.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9884 - auc: 0.9998 - val_loss: 0.9738 - val_tp: 13.0000 - val_fp: 19.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4062 - val_precision: 0.4062 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0092 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0085 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0076 - tp: 156.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9936 - auc: 1.0000 - val_loss: 1.1967 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0042 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1637 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0017 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0993 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0019 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3930 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.0015 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3728 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0014 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3756 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 7.3127e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6373 - val_tp: 13.0000 - val_fp: 19.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4062 - val_precision: 0.4062 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 186ms/step - loss: 0.9019 - tp: 120.0000 - fp: 34.0000 - tn: 127.0000 - fn: 39.0000 - accuracy: 0.7719 - precision: 0.7792 - recall: 0.7547 - auc: 0.8465 - val_loss: 0.6877 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9882\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0525 - tp: 153.0000 - fp: 1.0000 - tn: 159.0000 - fn: 7.0000 - accuracy: 0.9750 - precision: 0.9935 - recall: 0.9563 - auc: 0.9989 - val_loss: 0.6556 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20.0000 - val_fn: 12.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0159 - tp: 161.0000 - fp: 1.0000 - tn: 157.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9938 - recall: 0.9938 - auc: 0.9999 - val_loss: 0.6935 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.0075 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6826 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.0041 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6348 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20.0000 - val_fn: 12.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.0031 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6295 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 13.0000 - val_accuracy: 0.5938 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0016 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6626 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0021 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6320 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.0588 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 9.9372e-04 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5635 - val_tp: 3.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 11.0000 - val_accuracy: 0.6562 - val_precision: 1.0000 - val_recall: 0.2143 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0023 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4873 - val_tp: 7.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 7.0000 - val_accuracy: 0.7812 - val_precision: 1.0000 - val_recall: 0.5000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0013 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4155 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 4.0000 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.7500 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0018 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3371 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 6.8333e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2412 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 4.6118e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1361 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 4.7861e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1079 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 6s 276ms/step - loss: 0.4703 - tp: 144.0000 - fp: 16.0000 - tn: 140.0000 - fn: 20.0000 - accuracy: 0.8875 - precision: 0.9000 - recall: 0.8780 - auc: 0.9450 - val_loss: 0.6312 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0542 - tp: 152.0000 - fp: 2.0000 - tn: 164.0000 - fn: 2.0000 - accuracy: 0.9875 - precision: 0.9870 - recall: 0.9870 - auc: 0.9954 - val_loss: 0.6111 - val_tp: 17.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8095 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0277 - tp: 157.0000 - fp: 1.0000 - tn: 160.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9937 - recall: 0.9874 - auc: 0.9995 - val_loss: 0.6093 - val_tp: 8.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 7.0000 - val_accuracy: 0.7812 - val_precision: 1.0000 - val_recall: 0.5333 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.0119 - tp: 160.0000 - fp: 1.0000 - tn: 158.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9938 - recall: 0.9938 - auc: 0.9999 - val_loss: 0.6314 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0086 - tp: 169.0000 - fp: 1.0000 - tn: 150.0000 - fn: 0.0000e+00 - accuracy: 0.9969 - precision: 0.9941 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5655 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0019 - tp: 150.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5195 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.0015 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4682 - val_tp: 17.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8947 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0020 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4440 - val_tp: 14.0000 - val_fp: 2.0000 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8750 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0013 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3558 - val_tp: 18.0000 - val_fp: 2.0000 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.9000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0042 - tp: 160.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9938 - auc: 1.0000 - val_loss: 0.5545 - val_tp: 12.0000 - val_fp: 19.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4062 - val_precision: 0.3871 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0012 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2458 - val_tp: 20.0000 - val_fp: 1.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9524 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0012 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3908 - val_tp: 17.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5484 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0033 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3337 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7273 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0015 - tp: 151.0000 - fp: 0.0000e+00 - tn: 169.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1973 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 7.1019e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1160 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 0.9097 - tp: 116.0000 - fp: 44.0000 - tn: 116.0000 - fn: 44.0000 - accuracy: 0.7250 - precision: 0.7250 - recall: 0.7250 - auc: 0.8119 - val_loss: 0.6791 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0524 - tp: 156.0000 - fp: 2.0000 - tn: 157.0000 - fn: 5.0000 - accuracy: 0.9781 - precision: 0.9873 - recall: 0.9689 - auc: 0.9984 - val_loss: 0.6712 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0190 - tp: 156.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.6670 - val_tp: 9.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 5.0000 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.6429 - val_auc: 0.9484\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.0140 - tp: 158.0000 - fp: 1.0000 - tn: 160.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.6615 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0027 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6233 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 5.0000 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.6875 - val_auc: 1.0000\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0011 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5692 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0011 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4854 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 4.2877e-04 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4115 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 7.2509e-04 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3327 - val_tp: 18.0000 - val_fp: 1.0000 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9474 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 5.0455e-04 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3278 - val_tp: 15.0000 - val_fp: 2.0000 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 4.4728e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2667 - val_tp: 16.0000 - val_fp: 1.0000 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9412 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 6.0583e-04 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2661 - val_tp: 15.0000 - val_fp: 3.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9062 - val_precision: 0.8333 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 3.2235e-04 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2505 - val_tp: 16.0000 - val_fp: 4.0000 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 3.5395e-04 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1408 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 3.0878e-04 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1102 - val_tp: 18.0000 - val_fp: 1.0000 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9474 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 1.0421 - tp: 116.0000 - fp: 47.0000 - tn: 115.0000 - fn: 42.0000 - accuracy: 0.7219 - precision: 0.7117 - recall: 0.7342 - auc: 0.7623 - val_loss: 0.6715 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1313 - tp: 151.0000 - fp: 2.0000 - tn: 156.0000 - fn: 11.0000 - accuracy: 0.9594 - precision: 0.9869 - recall: 0.9321 - auc: 0.9861 - val_loss: 0.6747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0837 - tp: 150.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 8.0000 - accuracy: 0.9750 - precision: 1.0000 - recall: 0.9494 - auc: 0.9920 - val_loss: 0.6474 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.0482 - tp: 165.0000 - fp: 1.0000 - tn: 150.0000 - fn: 4.0000 - accuracy: 0.9844 - precision: 0.9940 - recall: 0.9763 - auc: 0.9985 - val_loss: 0.6520 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0465 - tp: 153.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 4.0000 - accuracy: 0.9875 - precision: 1.0000 - recall: 0.9745 - auc: 0.9981 - val_loss: 0.6283 - val_tp: 4.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 13.0000 - val_accuracy: 0.5938 - val_precision: 1.0000 - val_recall: 0.2353 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0762 - tp: 147.0000 - fp: 2.0000 - tn: 166.0000 - fn: 5.0000 - accuracy: 0.9781 - precision: 0.9866 - recall: 0.9671 - auc: 0.9936 - val_loss: 0.5939 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.0588 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0208 - tp: 168.0000 - fp: 0.0000e+00 - tn: 150.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9882 - auc: 1.0000 - val_loss: 0.5802 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 4.0000 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.7778 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0175 - tp: 143.0000 - fp: 1.0000 - tn: 175.0000 - fn: 1.0000 - accuracy: 0.9937 - precision: 0.9931 - recall: 0.9931 - auc: 0.9999 - val_loss: 0.4999 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 5.0000 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.6875 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0335 - tp: 161.0000 - fp: 1.0000 - tn: 156.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9938 - recall: 0.9877 - auc: 0.9992 - val_loss: 0.4807 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.7812 - val_precision: 1.0000 - val_recall: 0.6316 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0295 - tp: 176.0000 - fp: 0.0000e+00 - tn: 142.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9888 - auc: 0.9995 - val_loss: 0.3573 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8824 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0092 - tp: 145.0000 - fp: 0.0000e+00 - tn: 174.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9932 - auc: 1.0000 - val_loss: 0.2468 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8667 - val_auc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0056 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2709 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8947 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0019 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1777 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9444 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0013 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1256 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9375 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0011 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0916 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9474 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.6372 - tp: 124.0000 - fp: 38.0000 - tn: 118.0000 - fn: 40.0000 - accuracy: 0.7563 - precision: 0.7654 - recall: 0.7561 - auc: 0.8594 - val_loss: 0.6033 - val_tp: 15.0000 - val_fp: 16.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4839 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0889 - tp: 149.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 6.0000 - accuracy: 0.9812 - precision: 1.0000 - recall: 0.9613 - auc: 0.9906 - val_loss: 0.5125 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0585 - tp: 164.0000 - fp: 1.0000 - tn: 151.0000 - fn: 4.0000 - accuracy: 0.9844 - precision: 0.9939 - recall: 0.9762 - auc: 0.9976 - val_loss: 0.4889 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.0598 - tp: 154.0000 - fp: 2.0000 - tn: 160.0000 - fn: 4.0000 - accuracy: 0.9812 - precision: 0.9872 - recall: 0.9747 - auc: 0.9978 - val_loss: 0.4654 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0276 - tp: 160.0000 - fp: 1.0000 - tn: 156.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9938 - recall: 0.9816 - auc: 0.9997 - val_loss: 0.4473 - val_tp: 16.0000 - val_fp: 5.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.7619 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0274 - tp: 155.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 3.0000 - accuracy: 0.9906 - precision: 1.0000 - recall: 0.9810 - auc: 0.9996 - val_loss: 0.4281 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0251 - tp: 153.0000 - fp: 1.0000 - tn: 164.0000 - fn: 2.0000 - accuracy: 0.9906 - precision: 0.9935 - recall: 0.9871 - auc: 0.9996 - val_loss: 0.3088 - val_tp: 16.0000 - val_fp: 1.0000 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9412 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0074 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2239 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0039 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2640 - val_tp: 15.0000 - val_fp: 1.0000 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0014 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2118 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0010 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1784 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 9.2032e-04 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0751 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 6.9667e-04 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0592 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0013 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0386 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 4.8974e-04 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0186 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 6s 284ms/step - loss: 1.5377 - tp: 115.0000 - fp: 50.0000 - tn: 111.0000 - fn: 44.0000 - accuracy: 0.7063 - precision: 0.6970 - recall: 0.7233 - auc: 0.7846 - val_loss: 0.6011 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0837 - tp: 156.0000 - fp: 2.0000 - tn: 155.0000 - fn: 7.0000 - accuracy: 0.9719 - precision: 0.9873 - recall: 0.9571 - auc: 0.9945 - val_loss: 0.5446 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0647 - tp: 159.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 5.0000 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9695 - auc: 0.9952 - val_loss: 0.5442 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0432 - tp: 144.0000 - fp: 3.0000 - tn: 169.0000 - fn: 4.0000 - accuracy: 0.9781 - precision: 0.9796 - recall: 0.9730 - auc: 0.9990 - val_loss: 0.5654 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0117 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5384 - val_tp: 13.0000 - val_fp: 2.0000 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8667 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0094 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4755 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0113 - tp: 149.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9933 - auc: 1.0000 - val_loss: 0.4958 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0029 - tp: 173.0000 - fp: 0.0000e+00 - tn: 147.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3718 - val_tp: 19.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0064 - tp: 150.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4892 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0031 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2997 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0024 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3214 - val_tp: 15.0000 - val_fp: 2.0000 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8824 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0024 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1892 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0012 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1215 - val_tp: 20.0000 - val_fp: 0.0000e+00 - val_tn: 12.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 9.5277e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0906 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 8.6583e-04 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0686 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 1.0979 - tp: 111.0000 - fp: 43.0000 - tn: 115.0000 - fn: 51.0000 - accuracy: 0.7063 - precision: 0.7208 - recall: 0.6852 - auc: 0.7328 - val_loss: 0.5841 - val_tp: 14.0000 - val_fp: 4.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.7778 - val_recall: 1.0000 - val_auc: 0.9841\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1542 - tp: 147.0000 - fp: 6.0000 - tn: 157.0000 - fn: 10.0000 - accuracy: 0.9500 - precision: 0.9608 - recall: 0.9363 - auc: 0.9833 - val_loss: 0.5151 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8750 - val_auc: 0.9844\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0577 - tp: 158.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 5.0000 - accuracy: 0.9844 - precision: 1.0000 - recall: 0.9693 - auc: 0.9969 - val_loss: 0.4773 - val_tp: 6.0000 - val_fp: 0.0000e+00 - val_tn: 20.0000 - val_fn: 6.0000 - val_accuracy: 0.8125 - val_precision: 1.0000 - val_recall: 0.5000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0243 - tp: 157.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9874 - auc: 0.9999 - val_loss: 0.5268 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 6.0000 - val_accuracy: 0.8125 - val_precision: 1.0000 - val_recall: 0.6471 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0165 - tp: 162.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9939 - auc: 0.9999 - val_loss: 0.4639 - val_tp: 16.0000 - val_fp: 1.0000 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9412 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0056 - tp: 154.0000 - fp: 0.0000e+00 - tn: 166.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4610 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0031 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4600 - val_tp: 17.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.8095 - val_recall: 1.0000 - val_auc: 0.9961\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0012 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4152 - val_tp: 16.0000 - val_fp: 1.0000 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9412 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0010 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4269 - val_tp: 16.0000 - val_fp: 7.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.6957 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 7.8410e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3883 - val_tp: 15.0000 - val_fp: 4.0000 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8750 - val_precision: 0.7895 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 7.2781e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4960 - val_tp: 16.0000 - val_fp: 13.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5517 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 7.7127e-04 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3946 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7273 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 4.5923e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3047 - val_tp: 20.0000 - val_fp: 7.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.7407 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 2.9648e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4102 - val_tp: 17.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7188 - val_precision: 0.6538 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 2.0141e-04 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4365 - val_tp: 15.0000 - val_fp: 6.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7143 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 1.2370 - tp: 110.0000 - fp: 53.0000 - tn: 111.0000 - fn: 46.0000 - accuracy: 0.6906 - precision: 0.6748 - recall: 0.7051 - auc: 0.7371 - val_loss: 0.6456 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9375 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0851 - tp: 152.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 8.0000 - accuracy: 0.9750 - precision: 1.0000 - recall: 0.9500 - auc: 0.9964 - val_loss: 0.6471 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8750 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0526 - tp: 158.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 4.0000 - accuracy: 0.9875 - precision: 1.0000 - recall: 0.9753 - auc: 0.9957 - val_loss: 0.6504 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.0413 - tp: 154.0000 - fp: 1.0000 - tn: 161.0000 - fn: 4.0000 - accuracy: 0.9844 - precision: 0.9935 - recall: 0.9747 - auc: 0.9988 - val_loss: 0.6541 - val_tp: 16.0000 - val_fp: 14.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5333 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0289 - tp: 160.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 3.0000 - accuracy: 0.9906 - precision: 1.0000 - recall: 0.9816 - auc: 0.9998 - val_loss: 0.6436 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0185 - tp: 157.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.6359 - val_tp: 14.0000 - val_fp: 5.0000 - val_tn: 13.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.7368 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0108 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6010 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8571 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0060 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5918 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9961\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0031 - tp: 151.0000 - fp: 0.0000e+00 - tn: 169.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6101 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 0.9841\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0022 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5788 - val_tp: 13.0000 - val_fp: 17.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4333 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0021 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4626 - val_tp: 18.0000 - val_fp: 6.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8125 - val_precision: 0.7500 - val_recall: 1.0000 - val_auc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0020 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4774 - val_tp: 14.0000 - val_fp: 7.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0014 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3784 - val_tp: 16.0000 - val_fp: 5.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.8438 - val_precision: 0.7619 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0019 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2964 - val_tp: 17.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9688 - val_precision: 0.9444 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0011 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2178 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 188ms/step - loss: 0.1503 - tp: 153.0000 - fp: 11.0000 - tn: 147.0000 - fn: 9.0000 - accuracy: 0.9375 - precision: 0.9329 - recall: 0.9444 - auc: 0.9865 - val_loss: 0.6782 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0277 - tp: 154.0000 - fp: 2.0000 - tn: 162.0000 - fn: 2.0000 - accuracy: 0.9875 - precision: 0.9872 - recall: 0.9872 - auc: 0.9996 - val_loss: 0.6674 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9882\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.0018 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9961\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.0023 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 6.7142e-05 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6527 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 3.4690e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5713 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 5.0300e-05 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4811 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8125 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 1.0539e-04 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3888 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9333 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 5.4159e-05 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3163 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8750 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 4.9237e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2399 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9375 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 3.5603e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2191 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9333 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 3.1406e-05 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1565 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8947 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 5.0344e-05 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1415 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8571 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 2.5950e-05 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1122 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8824 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 7.5595e-05 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0677 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9333 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      " 1/20 [>.............................] - ETA: 1:09 - loss: 2.1438 - tp: 6.0000 - fp: 10.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.3750 - precision: 0.3750 - recall: 1.0000 - auc: 0.5833WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.267993). Check your callbacks.\n",
      "20/20 [==============================] - 6s 307ms/step - loss: 2.8111 - tp: 101.0000 - fp: 55.0000 - tn: 103.0000 - fn: 61.0000 - accuracy: 0.6375 - precision: 0.6474 - recall: 0.6235 - auc: 0.6682 - val_loss: 0.6936 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.8412\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.2707 - tp: 149.0000 - fp: 18.0000 - tn: 142.0000 - fn: 11.0000 - accuracy: 0.9094 - precision: 0.8922 - recall: 0.9312 - auc: 0.9696 - val_loss: 0.6822 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8027\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0422 - tp: 161.0000 - fp: 4.0000 - tn: 153.0000 - fn: 2.0000 - accuracy: 0.9812 - precision: 0.9758 - recall: 0.9877 - auc: 0.9992 - val_loss: 0.6903 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 15.0000 - val_accuracy: 0.5312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7941\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0355 - tp: 146.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 4.0000 - accuracy: 0.9875 - precision: 1.0000 - recall: 0.9733 - auc: 0.9995 - val_loss: 0.6721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8492\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0181 - tp: 165.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9880 - auc: 0.9999 - val_loss: 0.6924 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8711\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0145 - tp: 157.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9874 - auc: 0.9999 - val_loss: 0.7236 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 19.0000 - val_accuracy: 0.4062 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7753\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.0063 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7281 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8254\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0025 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6832 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8863\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0039 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6505 - val_tp: 5.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 12.0000 - val_accuracy: 0.6250 - val_precision: 1.0000 - val_recall: 0.2941 - val_auc: 0.8706\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0019 - tp: 155.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6403 - val_tp: 4.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 13.0000 - val_accuracy: 0.5938 - val_precision: 1.0000 - val_recall: 0.2353 - val_auc: 0.9137\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0027 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5439 - val_tp: 5.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 9.0000 - val_accuracy: 0.7188 - val_precision: 1.0000 - val_recall: 0.3571 - val_auc: 0.9524\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0032 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5225 - val_tp: 5.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 11.0000 - val_accuracy: 0.6562 - val_precision: 1.0000 - val_recall: 0.3125 - val_auc: 0.9766\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0025 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4849 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 4.0000 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.7500 - val_auc: 0.9766\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0019 - tp: 153.0000 - fp: 0.0000e+00 - tn: 167.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4226 - val_tp: 13.0000 - val_fp: 0.0000e+00 - val_tn: 13.0000 - val_fn: 6.0000 - val_accuracy: 0.8125 - val_precision: 1.0000 - val_recall: 0.6842 - val_auc: 0.9960\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0017 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3391 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8889 - val_auc: 0.9980\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 165ms/step - loss: 1.0787 - tp: 120.0000 - fp: 48.0000 - tn: 109.0000 - fn: 43.0000 - accuracy: 0.7156 - precision: 0.7143 - recall: 0.7362 - auc: 0.7696 - val_loss: 0.6875 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9118\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0741 - tp: 151.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 7.0000 - accuracy: 0.9781 - precision: 1.0000 - recall: 0.9557 - auc: 0.9976 - val_loss: 0.6836 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5625 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.6944\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0241 - tp: 157.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9874 - auc: 0.9998 - val_loss: 0.7297 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.4688\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0118 - tp: 154.0000 - fp: 1.0000 - tn: 165.0000 - fn: 0.0000e+00 - accuracy: 0.9969 - precision: 0.9935 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7162 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.8176\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 34ms/step - loss: 0.0049 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7434 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.8941\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0028 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7538 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 0.9627\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0027 - tp: 156.0000 - fp: 0.0000e+00 - tn: 164.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6858 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9627\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.0014 - tp: 162.0000 - fp: 0.0000e+00 - tn: 158.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6990 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 0.9686\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0014 - tp: 150.0000 - fp: 0.0000e+00 - tn: 170.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5807 - val_tp: 19.0000 - val_fp: 13.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5938 - val_precision: 0.5938 - val_recall: 1.0000 - val_auc: 0.9919\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.0025 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7108 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.9844\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.0016 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5911 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 5.1217e-04 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5797 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 5.9529e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5514 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 4.2347e-04 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5115 - val_tp: 15.0000 - val_fp: 11.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6562 - val_precision: 0.5769 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 5.0084e-04 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3843 - val_tp: 16.0000 - val_fp: 7.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.6957 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Submodel:  coronal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.5754 - tp: 134.0000 - fp: 25.0000 - tn: 135.0000 - fn: 26.0000 - accuracy: 0.8406 - precision: 0.8428 - recall: 0.8375 - auc: 0.9038 - val_loss: 0.7006 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0693 - tp: 155.0000 - fp: 2.0000 - tn: 160.0000 - fn: 3.0000 - accuracy: 0.9844 - precision: 0.9873 - recall: 0.9810 - auc: 0.9902 - val_loss: 0.7074 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0338 - tp: 151.0000 - fp: 1.0000 - tn: 165.0000 - fn: 3.0000 - accuracy: 0.9875 - precision: 0.9934 - recall: 0.9805 - auc: 0.9991 - val_loss: 0.7555 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.0741 - tp: 153.0000 - fp: 3.0000 - tn: 158.0000 - fn: 6.0000 - accuracy: 0.9719 - precision: 0.9808 - recall: 0.9623 - auc: 0.9958 - val_loss: 0.6414 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 20.0000 - val_fn: 12.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0186 - tp: 166.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9881 - auc: 0.9998 - val_loss: 0.6621 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 19.0000 - val_fn: 13.0000 - val_accuracy: 0.5938 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0054 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8336 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0050 - tp: 168.0000 - fp: 0.0000e+00 - tn: 152.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7508 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0017 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.8458 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 17.0000 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0023 - tp: 157.0000 - fp: 0.0000e+00 - tn: 163.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.7348 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 1.0000 - val_recall: 0.0588 - val_auc: 1.0000\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 36ms/step - loss: 0.0012 - tp: 169.0000 - fp: 0.0000e+00 - tn: 151.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6199 - val_tp: 3.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 13.0000 - val_accuracy: 0.5938 - val_precision: 1.0000 - val_recall: 0.1875 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0013 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5918 - val_tp: 5.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 13.0000 - val_accuracy: 0.5938 - val_precision: 1.0000 - val_recall: 0.2778 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 6.8555e-04 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3975 - val_tp: 8.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.7188 - val_precision: 1.0000 - val_recall: 0.4706 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 7.8760e-04 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3227 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 5.0000 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.7059 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 4.5655e-04 - tp: 151.0000 - fp: 0.0000e+00 - tn: 169.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1649 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8235 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.0016 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0910 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 1.0000 - val_accuracy: 0.9688 - val_precision: 1.0000 - val_recall: 0.9333 - val_auc: 1.0000\n",
      "Submodel:  sagittal\n",
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 0.5445 - tp: 130.0000 - fp: 28.0000 - tn: 130.0000 - fn: 32.0000 - accuracy: 0.8125 - precision: 0.8228 - recall: 0.8025 - auc: 0.9074 - val_loss: 0.6317 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.8333 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0402 - tp: 156.0000 - fp: 1.0000 - tn: 159.0000 - fn: 4.0000 - accuracy: 0.9844 - precision: 0.9936 - recall: 0.9750 - auc: 0.9992 - val_loss: 0.6584 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 14.0000 - val_accuracy: 0.5625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.0140 - tp: 158.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.6483 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 4.0000 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.7500 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.0040 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6557 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 16.0000 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 8.3618e-04 - tp: 163.0000 - fp: 0.0000e+00 - tn: 157.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6410 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 18.0000 - val_accuracy: 0.4375 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 6.3709e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5711 - val_tp: 3.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 12.0000 - val_accuracy: 0.6250 - val_precision: 1.0000 - val_recall: 0.2000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 7.0089e-04 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5007 - val_tp: 10.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7812 - val_precision: 1.0000 - val_recall: 0.5882 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 4.5438e-04 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4269 - val_tp: 14.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 4.0000 - val_accuracy: 0.8750 - val_precision: 1.0000 - val_recall: 0.7778 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 2.5815e-04 - tp: 167.0000 - fp: 0.0000e+00 - tn: 153.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3120 - val_tp: 11.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 3.0000 - val_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.7857 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 1.5996e-04 - tp: 149.0000 - fp: 0.0000e+00 - tn: 171.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2311 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 18.0000 - val_fn: 2.0000 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8571 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 3.7829e-04 - tp: 165.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1438 - val_tp: 16.0000 - val_fp: 0.0000e+00 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 2.4904e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1062 - val_tp: 18.0000 - val_fp: 0.0000e+00 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 3.0274e-04 - tp: 164.0000 - fp: 0.0000e+00 - tn: 156.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0743 - val_tp: 12.0000 - val_fp: 0.0000e+00 - val_tn: 20.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 3.8058e-04 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0481 - val_tp: 17.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 37ms/step - loss: 3.4656e-04 - tp: 161.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0349 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "axial (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sagittal (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coronal (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          axial[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 8)    80          sagittal[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 8)    80          coronal[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 8)    32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 8)    32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 8)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 8)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 8)    584         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 8)    584         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 8)    32          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 8)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 8)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 8)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1168        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2048)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_node (Dense)             (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 580,265\n",
      "Trainable params: 579,593\n",
      "Non-trainable params: 672\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Submodel:  combined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL BATCH SIZE:  16\n",
      "20\n",
      "Train for 20 steps, validate for 2 steps\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 5s 257ms/step - loss: 1.2424 - tp: 109.0000 - fp: 49.0000 - tn: 114.0000 - fn: 48.0000 - accuracy: 0.6969 - precision: 0.6899 - recall: 0.6943 - auc: 0.7783 - val_loss: 0.6719 - val_tp: 8.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 7.0000 - val_accuracy: 0.7812 - val_precision: 1.0000 - val_recall: 0.5333 - val_auc: 1.0000\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0884 - tp: 157.0000 - fp: 4.0000 - tn: 151.0000 - fn: 8.0000 - accuracy: 0.9625 - precision: 0.9752 - recall: 0.9515 - auc: 0.9954 - val_loss: 0.6640 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0734 - tp: 152.0000 - fp: 3.0000 - tn: 160.0000 - fn: 5.0000 - accuracy: 0.9750 - precision: 0.9806 - recall: 0.9682 - auc: 0.9938 - val_loss: 0.6531 - val_tp: 15.0000 - val_fp: 0.0000e+00 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 1s 65ms/step - loss: 0.0220 - tp: 154.0000 - fp: 0.0000e+00 - tn: 165.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9935 - auc: 0.9995 - val_loss: 0.6332 - val_tp: 17.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.7083 - val_recall: 1.0000 - val_auc: 0.9882\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0186 - tp: 163.0000 - fp: 0.0000e+00 - tn: 155.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9879 - auc: 0.9999 - val_loss: 0.6166 - val_tp: 14.0000 - val_fp: 1.0000 - val_tn: 16.0000 - val_fn: 1.0000 - val_accuracy: 0.9375 - val_precision: 0.9333 - val_recall: 0.9333 - val_auc: 0.9961\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0163 - tp: 156.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 2.0000 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.6601 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.0088 - tp: 160.0000 - fp: 0.0000e+00 - tn: 159.0000 - fn: 1.0000 - accuracy: 0.9969 - precision: 1.0000 - recall: 0.9938 - auc: 1.0000 - val_loss: 0.7306 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 0.0044 - tp: 158.0000 - fp: 0.0000e+00 - tn: 162.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.6026 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5312 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0055 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.9401 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.0069 - tp: 169.0000 - fp: 1.0000 - tn: 150.0000 - fn: 0.0000e+00 - accuracy: 0.9969 - precision: 0.9941 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5777 - val_tp: 14.0000 - val_fp: 18.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4375 - val_precision: 0.4375 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.0019 - tp: 152.0000 - fp: 0.0000e+00 - tn: 168.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5920 - val_tp: 15.0000 - val_fp: 17.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.4688 - val_precision: 0.4688 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.0014 - tp: 159.0000 - fp: 0.0000e+00 - tn: 161.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.3779 - val_tp: 19.0000 - val_fp: 12.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.6129 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0016 - tp: 166.0000 - fp: 0.0000e+00 - tn: 154.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4816 - val_tp: 15.0000 - val_fp: 15.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5312 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0033 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4022 - val_tp: 14.0000 - val_fp: 7.0000 - val_tn: 11.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7812 - val_precision: 0.6667 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.0014 - tp: 160.0000 - fp: 0.0000e+00 - tn: 160.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2017 - val_tp: 14.0000 - val_fp: 2.0000 - val_tn: 16.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9375 - val_precision: 0.8750 - val_recall: 1.0000 - val_auc: 1.0000\n",
      "{0: 1.0, 1: 1.0}\n",
      "Submodel:  axial\n",
      "GLOBAL BATCH SIZE:  16\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "no files found for pattern '/work/06850/sbansal6/maverick2/mriqc-shared/experiment_faced_refaced/exp_face_refaced/tfrecords_F15/tfrecords_fold_15/data-train_*'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2e208fe76170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-2e208fe76170>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(volume_shape, image_size, dropout, batch_size, n_classes, n_epochs, fold)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mvolume_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvolume_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mplane\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplane\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mshuffle_buffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-af066be328e0>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(file_pattern, n_classes, batch_size, volume_shape, plane, n, block_shape, n_epochs, mapping, augment, shuffle_buffer_size, num_parallel_calls)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no files found for pattern '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mcompressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_is_gzipped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no files found for pattern '/work/06850/sbansal6/maverick2/mriqc-shared/experiment_faced_refaced/exp_face_refaced/tfrecords_F15/tfrecords_fold_15/data-train_*'"
     ]
    }
   ],
   "source": [
    "# Std packages\n",
    "import sys, os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "sys.path.append(\"../defacing\")\n",
    "\n",
    "# Custom packages\n",
    "from models import modelN\n",
    "# from dataloaders.dataset import get_dataset\n",
    "\n",
    "# Tf packages\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    LearningRateScheduler,\n",
    "    TensorBoard,\n",
    ")\n",
    "# import nobrainer\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "ROOTDIR = '/work/06850/sbansal6/maverick2/mriqc-shared/experiment_faced_refaced/exp_face_refaced'\n",
    "\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch < 3:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
    "\n",
    "\n",
    "def train(\n",
    "    volume_shape=(64, 64, 64),\n",
    "    image_size=(64, 64),\n",
    "    dropout=0.2,\n",
    "    batch_size=16,\n",
    "    n_classes=2,\n",
    "    n_epochs=15,\n",
    "    fold=1\n",
    "):\n",
    "    \n",
    "    \n",
    "#     print(\"FOLD {}\".format(fold))\n",
    "    dir_path = os.path.join(ROOTDIR, \"csv_F15/train_test_fold_{}/csv\".format(fold))\n",
    "\n",
    "    train_csv_path = os.path.join(dir_path, \"training.csv\")\n",
    "    valid_csv_path = os.path.join(dir_path, \"validation.csv\")\n",
    "\n",
    "    train_paths = pd.read_csv(train_csv_path)[\"X\"].values\n",
    "    valid_paths = pd.read_csv(valid_csv_path)[\"X\"].values\n",
    "    \n",
    "    train_labels = pd.read_csv(train_csv_path)[\"Y\"].values\n",
    "    valid_labels = pd.read_csv(valid_csv_path)[\"Y\"].values\n",
    "    \n",
    "    weights = class_weight.compute_class_weight('balanced',\n",
    "                                                np.unique(train_labels),\n",
    "                                                train_labels)\n",
    "    weights = dict(enumerate(weights))\n",
    "    \n",
    "    print(weights)\n",
    "    \n",
    "    planes = [\"axial\", \"coronal\", \"sagittal\", \"combined\"]\n",
    "\n",
    "#     strategy = tf.distribute.MirroredStrategy()\n",
    "#     BATCH_SIZE_PER_REPLICA = batch_size\n",
    "#     global_batch_size = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "    global_batch_size = batch_size\n",
    "    \n",
    "    model_save_path = os.path.join(ROOTDIR, \"model_save_dir_F15_3DS/train_test_fold_{}\".format(fold))\n",
    "    \n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "    cp_save_path = os.path.join(model_save_path, \"weights\")\n",
    "\n",
    "    logdir_path = os.path.join(model_save_path, \"tb_logs\")\n",
    "    if not os.path.exists(logdir_path):\n",
    "        os.makedirs(logdir_path)\n",
    "\n",
    "    for plane in planes:\n",
    "\n",
    "        logdir = os.path.join(logdir_path, plane)\n",
    "        os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "        tbCallback = TensorBoard(\n",
    "            log_dir=logdir, histogram_freq=1, write_graph=True, write_images=True,\n",
    "        )\n",
    "\n",
    "        os.makedirs(os.path.join(cp_save_path, plane), exist_ok=True)\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint(\n",
    "            os.path.join(cp_save_path, plane, \"best-wts.h5\"),\n",
    "            monitor=\"val_loss\",\n",
    "            save_weights_only=True,\n",
    "            mode=\"min\",\n",
    "        )\n",
    "\n",
    "#         with strategy.scope():\n",
    "\n",
    "        if not plane == \"combined\": \n",
    "            lr = 1e-3\n",
    "            model = modelN.Submodel(\n",
    "                input_shape=image_size,\n",
    "                dropout=dropout,\n",
    "                name=plane,\n",
    "                include_top=True,\n",
    "                weights=None,\n",
    "            )\n",
    "        else:\n",
    "            lr = 5e-4\n",
    "            model = modelN.CombinedClassifier(\n",
    "                input_shape=image_size,\n",
    "                dropout=dropout,\n",
    "                trainable=True,\n",
    "                wts_root=cp_save_path,\n",
    "            )\n",
    "\n",
    "        print(\"Submodel: \", plane)\n",
    "#         print(model.summary())\n",
    "\n",
    "        METRICS = [\n",
    "            metrics.TruePositives(name=\"tp\"),\n",
    "            metrics.FalsePositives(name=\"fp\"),\n",
    "            metrics.TrueNegatives(name=\"tn\"),\n",
    "            metrics.FalseNegatives(name=\"fn\"),\n",
    "            metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "            metrics.Precision(name=\"precision\"),\n",
    "            metrics.Recall(name=\"recall\"),\n",
    "            metrics.AUC(name=\"auc\"),\n",
    "        ]\n",
    "\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.binary_crossentropy,\n",
    "            optimizer=Adam(learning_rate=lr),\n",
    "            metrics=METRICS,\n",
    "        )\n",
    "\n",
    "        print(\"GLOBAL BATCH SIZE: \", global_batch_size)\n",
    "\n",
    "        dataset_train = get_dataset(\n",
    "            file_pattern=os.path.join(ROOTDIR, \"tfrecords_F15/tfrecords_fold_{}/data-train_*\".format(fold)),\n",
    "            n_classes=n_classes,\n",
    "            batch_size=global_batch_size,\n",
    "            volume_shape=volume_shape,\n",
    "            plane=plane,\n",
    "            shuffle_buffer_size=global_batch_size,\n",
    "        )\n",
    "\n",
    "        dataset_valid = get_dataset(\n",
    "            file_pattern=os.path.join(ROOTDIR, \"tfrecords_F15/tfrecords_fold_{}/data-valid_*\".format(fold)),\n",
    "            n_classes=n_classes,\n",
    "            batch_size=global_batch_size,\n",
    "            volume_shape=volume_shape,\n",
    "            plane=plane,\n",
    "            shuffle_buffer_size=global_batch_size,\n",
    "        )\n",
    "        \n",
    "        steps_per_epoch = math.ceil(len(train_paths)/batch_size)\n",
    "\n",
    "        validation_steps = math.ceil(len(valid_paths)/batch_size)\n",
    "\n",
    "        print(steps_per_epoch)\n",
    "    \n",
    "\n",
    "        lrcallback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "        \n",
    "        model.fit(\n",
    "            dataset_train,\n",
    "            epochs=n_epochs,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=dataset_valid,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=[tbCallback, model_checkpoint],\n",
    "            class_weight = weights,\n",
    "        )\n",
    "\n",
    "        del model\n",
    "        K.clear_session()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for fold in range(1, 16):\n",
    "        train(fold=fold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import imgaug\n",
    "import shutil\n",
    "import numpy as np\n",
    "from imgaug import augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../defacing')\n",
    "from helpers.utils import save_vol, load_vol\n",
    "from preprocessing.conform import conform_data\n",
    "from preprocessing.normalization import clip, standardize, normalize\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class DataGeneratoronFly(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, conform_size=(64, 64, 64),\n",
    "                        conform_zoom=(4., 4., 4.), \n",
    "                        nchannels=1, \n",
    "                        nruns=8,\n",
    "                        nsamples=20,\n",
    "                        save=False, \n",
    "                        transform=None):\n",
    "\n",
    "        self.conform_size=conform_size\n",
    "        self.conform_zoom=conform_zoom\n",
    "        self.nchannels=nchannels\n",
    "        self.transform=transform\n",
    "        self.nsamples=nsamples\n",
    "        self.nruns=nruns\n",
    "        self.save=save\n",
    "        DISTRIBUTION = load_vol('../defacing/helpers/distribution.nii.gz')[0]\n",
    "        assert DISTRIBUTION.shape == conform_size, \"Invalid conform_size needs to regenerate face distribution\"\n",
    "\n",
    "        DISTRIBUTION /= DISTRIBUTION.sum()\n",
    "        self.sampler = lambda n: np.array([ np.unravel_index(\n",
    "                  np.random.choice(np.arange(np.prod(DISTRIBUTION.shape)),\n",
    "                                             p = DISTRIBUTION.ravel()),\n",
    "                  DISTRIBUTION.shape) for _ in range(n)]) \n",
    "\n",
    "\n",
    "\n",
    "    def _augmentation(self, volume):\n",
    "        r\"\"\"\n",
    "                Augmenters that are safe to apply to masks\n",
    "                Some, such as Affine, have settings that make them unsafe, so always\n",
    "                test your augmentation on masks\n",
    "        \"\"\"\n",
    "        volume_shape = volume.shape\n",
    "        det = self.transform.to_deterministic()\n",
    "        volume = det.augment_image(volume)\n",
    "\n",
    "        assert volume.shape == volume_shape, \"Augmentation shouldn't change volume size\"\n",
    "        return volume\n",
    "\n",
    "\n",
    "    def _sample_slices(self, volume, plane=None):\n",
    "\n",
    "        options = [\"axial\", \"coronal\", \"sagittal\", \"combined\"]\n",
    "        assert plane in options, \"expected plane to be one of ['axial', 'coronal', 'sagittal']\"\n",
    "        samples = self.sampler(self.nsamples)\n",
    "\n",
    "        if plane == \"sagittal\":\n",
    "            midx = samples[:, 0]\n",
    "            volume = volume\n",
    "            k = 3\n",
    "\n",
    "        if plane == \"coronal\":\n",
    "            midx = samples[:, 1]\n",
    "            volume = np.transpose(volume, axes=[1, 2, 0])\n",
    "            k = 2\n",
    "\n",
    "        if plane == \"axial\":\n",
    "            midx = samples[:, 2]\n",
    "            volume = np.transpose(volume, axes=[2, 0, 1])\n",
    "            k = 1\n",
    "\n",
    "        if plane == \"combined\":\n",
    "            temp = []\n",
    "            for op in options[:-1]:\n",
    "                temp.append(self._sample_slices(volume, op))\n",
    "            volume = temp\n",
    "#             plt.subplot(1, 3, 1)\n",
    "#             plt.imshow(volume[0][:,:,0])\n",
    "#             plt.subplot(1, 3, 2)\n",
    "#             plt.imshow(volume[1][:,:,0])\n",
    "#             plt.subplot(1, 3, 3)\n",
    "#             plt.imshow(volume[2][:,:,0])\n",
    "#             plt.show()\n",
    "\n",
    "        if not plane == \"combined\":\n",
    "            volume = np.squeeze(volume[midx,:,:])\n",
    "            volume = np.mean(volume, axis=0)\n",
    "            volume = np.rot90(volume, k)\n",
    "            volume = volume[..., None]\n",
    "        return volume\n",
    "\n",
    "\n",
    "    def get_data(self, volume):\n",
    "        # Generate indexes of the batch\n",
    "        volume = clip(volume, q=90)\n",
    "        volume = normalize(volume)\n",
    "        volume = standardize(volume)\n",
    "        newaffine = np.eye(4)\n",
    "        newaffine[:3, 3] = -0.5 * (np.array(self.conform_size) - 1)\n",
    "        os.makedirs('./tmp', exist_ok=True)\n",
    "        save_vol('./tmp/Pre-processing.nii.gz', volume, newaffine)\n",
    "        conform_data('./tmp/Pre-processing.nii.gz',\n",
    "                        './tmp/Conformed.nii.gz',\n",
    "                        self.conform_size,\n",
    "                        self.conform_zoom)\n",
    "\n",
    "        volume = load_vol('./tmp/Conformed.nii.gz')[0]\n",
    "\n",
    "        if self.transform:\n",
    "            volume = self._augmentation(volume)\n",
    "\n",
    "        slices = []\n",
    "        for _ in range(self.nruns):\n",
    "            slices.append(self._sample_slices(volume, \n",
    "                                    plane=\"combined\"))\n",
    "\n",
    "        if not self.save: \n",
    "            shutil.rmtree('./tmp')\n",
    "        return slices\n",
    "\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    path = '../sample_vols/defaced/example2.nii.gz'\n",
    "    \n",
    "    vol, _, _ = load_vol(path)\n",
    "    \n",
    "    \n",
    "    inference_transform_params = {\n",
    "            \"conform_size\": (64, 64, 64),\n",
    "            \"conform_zoom\": (4., 4., 4.), \n",
    "            \"nchannels\": 1, \n",
    "            \"nruns\": 8,\n",
    "            \"nsamples\": 24,\n",
    "            \"save\": False, \n",
    "            \"transform\": None\n",
    "        }\n",
    "    \n",
    "    inference_generator = DataGeneratoronFly(**inference_transform_params)\n",
    "    \n",
    "    slices = inference_generator.get_data(vol)\n",
    "    \n",
    "    slices = np.transpose(np.array(slices),axes=[1, 0, 2, 3, 4])\n",
    "    ds = {}\n",
    "    ds['axial'] = slices[0]\n",
    "    ds['coronal'] = slices[1]\n",
    "    ds['sagittal'] = slices[2]\n",
    "    \n",
    "#     print(ds)\n",
    "    print(slices.shape)\n",
    "#         return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "sys.path.append('../defacing')\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from models.modelN import CombinedClassifier\n",
    "# from dataloaders.inference_dataloader import DataGeneratoronFly\n",
    "\n",
    "ROOTDIR = \"/work/06850/sbansal6/maverick2/mriqc-shared/experiment_data_all\"\n",
    "\n",
    "\n",
    "class inferer(object):\n",
    "    \"\"\"\n",
    "       nMontecarlo: for multiple exp for same model\n",
    "       quick: checks for all 3 fold models\n",
    "       mode: method to merge predictions\n",
    "             allowed ['avg', 'max_vote']\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nMontecarlo=8, mode=\"avg\"):\n",
    "        r\"\"\"\n",
    "        \"\"\"\n",
    "        inference_transform_params = {\n",
    "            \"conform_size\": (64, 64, 64),\n",
    "            \"conform_zoom\": (4., 4., 4.), \n",
    "            \"nchannels\": 1, \n",
    "            \"nruns\": 8,\n",
    "            \"nsamples\": 20,\n",
    "            \"save\": False, \n",
    "            \"transform\": None\n",
    "        }\n",
    "\n",
    "        self.mode = mode\n",
    "        assert self.mode.lower() in [\n",
    "            \"avg\",\n",
    "            \"max_vote\",\n",
    "        ], \"unknown mode, allowed mode are ['avg', 'max_vote']\"\n",
    "\n",
    "        self.inference_generator = DataGeneratoronFly(**inference_transform_params)\n",
    "        self.model = CombinedClassifier(\n",
    "            input_shape=(64, 64), dropout=0.4, wts_root=None, trainable=True\n",
    "        )\n",
    "        self.model.load_weights(\n",
    "\n",
    "            os.path.abspath(os.path.join(ROOTDIR, \"model_save_dir_final_1/weights/combined/best-wts.h5\"))\n",
    "        )\n",
    "\n",
    "    def infer(self, vol):\n",
    "        \"\"\"\n",
    "        vol : can be numpy ndarray or path to volume\n",
    "        \"\"\"\n",
    "        slices = self.inference_generator.get_data(vol)\n",
    "        slices = np.transpose(np.array(slices),axes=[1, 0, 2, 3, 4])\n",
    "        \n",
    "        ds = {}\n",
    "        ds['axial'] = slices[0]\n",
    "        ds['coronal'] = slices[1]\n",
    "        ds['sagittal'] = slices[2]\n",
    "    \n",
    "        predictions = self.model.predict(ds)\n",
    "\n",
    "        if self.mode.lower() == \"max_vote\":\n",
    "            predictions = np.round(predictions)\n",
    "            unique_elements = np.unique(predictions)\n",
    "            count_array = np.array(\n",
    "                [\n",
    "                    sum(predictions == unique_element)\n",
    "                    for unique_element in unique_elements\n",
    "                ]\n",
    "            )\n",
    "            pred = (\n",
    "                np.argmax(count_array) if len(count_array) > 1 else unique_elements[0]\n",
    "            )\n",
    "            conf = (\n",
    "                1\n",
    "                if len(count_array) == 1\n",
    "                else count_array[pred] * 1.0 / np.sum(count_array)\n",
    "            )\n",
    "        elif self.mode.lower() == \"avg\":\n",
    "            conf = np.mean(predictions)\n",
    "            pred = np.round(conf)\n",
    "\n",
    "        pred_str = \"faced\" if pred == 1 else \"defaced\"\n",
    "        conf = conf if pred == 1 else 1.0 - conf\n",
    "\n",
    "        print(\"[INFO] Given volume is \" + pred_str + \" with confidence of: {}\".format(conf))\n",
    "        \n",
    "#         del self.model\n",
    "#         K.clear_session()\n",
    "        \n",
    "        return pred, conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import shap\n",
    "import glob\n",
    "\n",
    "sys.path.append('../defacing')\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from models.modelN import CombinedClassifier\n",
    "\n",
    "ROOTDIR = \"/work/06850/sbansal6/maverick2/mriqc-shared/experiment_data_all\"\n",
    "\n",
    "\n",
    "model = CombinedClassifier(\n",
    "            input_shape=(64, 64), dropout=0.4, wts_root=None, trainable=True\n",
    "        )\n",
    "\n",
    "model.load_weights(\n",
    "\n",
    "            os.path.abspath(os.path.join(ROOTDIR, \"model_save_dir_final_1/weights/combined/best-wts.h5\"))\n",
    "        )\n",
    "\n",
    "paths = glob.glob('/work/01329/poldrack/data/mriqc-net/data/test_images/test1_images/*/*')\n",
    "file = paths[0]\n",
    "vol, _, _ = load_vol(file)\n",
    "\n",
    "\n",
    "inference_transform_params = {\n",
    "    \"conform_size\": (64, 64, 64),\n",
    "    \"conform_zoom\": (4., 4., 4.), \n",
    "    \"nchannels\": 1, \n",
    "    \"nruns\": 8,\n",
    "    \"nsamples\": 20,\n",
    "    \"save\": False, \n",
    "    \"transform\": None\n",
    "}\n",
    "\n",
    "\n",
    "inference_generator = DataGeneratoronFly(**inference_transform_params)\n",
    "\n",
    "        \n",
    "slices = inference_generator.get_data(vol)\n",
    "slices = np.transpose(np.array(slices),axes=[1, 0, 2, 3, 4])\n",
    "        \n",
    "ds = {}\n",
    "ds['axial'] = slices[0]\n",
    "ds['coronal'] = slices[1]\n",
    "ds['sagittal'] = slices[2]\n",
    "# print(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "sys.path.append('../defacing')\n",
    "from helpers.utils import load_vol\n",
    "# from defacing.inference import inferer\n",
    "\n",
    "_inferer = inferer()\n",
    "# path = '../sample_vols/faced/example1.nii.gz'\n",
    "paths = glob.glob('/work/01329/poldrack/data/mriqc-net/data/test_images/test1_images/*/*')\n",
    "\n",
    "inf = {}\n",
    "\n",
    "for file in paths:\n",
    "    print(file)\n",
    "    temp = {}\n",
    "    vol, _, _ = load_vol(file)\n",
    "    label, conf = _inferer.infer(vol)\n",
    "    temp['label'] = label\n",
    "    temp['confidence'] = conf\n",
    "    inf[file.split('/')[-2] + '/' + file.split('/')[-1]] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(inf).transpose()\n",
    "\n",
    "df.to_csv('test_inference_aug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inference_results_path = 'test_inference.csv'\n",
    "data = pd.read_csv(inference_results_path)\n",
    "data.rename(columns={'Unnamed: 0':'volume'}, inplace=True )\n",
    "\n",
    "\n",
    "true_labels = pd.read_csv('/work/06850/sbansal6/maverick2/mriqc-net/2.5D/csv/faced/all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes, tlabels = true_labels['X'].values, true_labels['Y'].values\n",
    "\n",
    "tvolumes = {}\n",
    "\n",
    "for v in range(len(volumes)):\n",
    "    \n",
    "    tvolumes[volumes[v].split('/')[-2] + '/' + volumes[v].split('/')[-1]] = tlabels[v]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "true_labels = pd.read_csv('test1_images_gt.csv')\n",
    "tl_dict = {}\n",
    "for i, row in enumerate(true_labels.values):\n",
    "    \n",
    "    dataset, volume, label = row\n",
    "    l = 0 if 'deface' in label else 1\n",
    "    tl_dict[str(dataset) + '/' + str(volume)] = l\n",
    "    \n",
    "# print(tl_dict)\n",
    "    \n",
    "\n",
    "predicted = pd.read_csv('test_inference.csv')\n",
    "predicted.rename(columns={'Unnamed: 0':'volume'}, inplace=True )\n",
    "\n",
    "remove_vols = [\n",
    "    'ds001919',\n",
    "    'ds000148'\n",
    "]\n",
    "correct = 0\n",
    "incorrect = {}\n",
    "for i, row in enumerate(predicted.values):\n",
    "    volume, confidence, label = row\n",
    "    \n",
    "    if volume in tl_dict:\n",
    "        if label == tl_dict[volume]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            if 'ds001919' not in volume and 'ds000206' not in volume:\n",
    "                print(volume, confidence, label, tl_dict[volume])\n",
    "                incorrect[volume] = {}\n",
    "                incorrect[volume]['label'] = label\n",
    "                incorrect[volume]['confidence'] = confidence\n",
    "            \n",
    "print(len(incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct, len(incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpaths = glob.glob('/work/06850/sbansal6/maverick2/mriqc-shared/test_conformed/*/*')\n",
    "\n",
    "labels = []\n",
    "for c in cpaths:\n",
    "    name = '/'.join(c.rsplit('/', 2)[-2:])\n",
    "    print(name, tl_dict[name], incorrect[name]['label'])\n",
    "    labels.append(tl_dict[name])\n",
    "    \n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../defacing')\n",
    "\n",
    "import numpy as np\n",
    "# from scipy.misc import toimage\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from helpers.utils import save_vol, load_vol\n",
    "from preprocessing.conform import conform_data\n",
    "from preprocessing.normalization import clip, standardize, normalize\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conform_size = (128, 128, 128)\n",
    "conform_zoom = (1.5, 1.5, 1.5)\n",
    "\n",
    "testpath = '/work/01329/poldrack/data/mriqc-net/data/test_images/test1_images'\n",
    "\n",
    "# for f in incorrect:\n",
    "    \n",
    "#     dname = f.split('/')[0]\n",
    "#     fname = f.split('/')[1]\n",
    "#     print(dname, fname)\n",
    "    \n",
    "#     file = os.path.join(testpath, f)\n",
    "#     print(file)\n",
    "    \n",
    "#     cpath = '/work/06850/sbansal6/maverick2/mriqc-shared/test_conformed'\n",
    "#     outfile = os.path.join(cpath, dname)\n",
    "#     print(outfile)\n",
    "#     os.makedirs(outfile, exist_ok=True)\n",
    "    \n",
    "#     outfile = os.path.join(outfile, fname)\n",
    "#     print(outfile)\n",
    "#     conform_data(file, \n",
    "#                  out_file=outfile, \n",
    "#                  out_size=conform_size, \n",
    "#                  out_zooms=conform_zoom)\n",
    "    \n",
    "#     vol,_,_ = load_vol(outfile)\n",
    "    \n",
    "#     vol = np.array(vol)\n",
    "#     vol = np.transpose(vol, axes=[1, 2, 0])\n",
    "    \n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     for i in range(1, 11):\n",
    "#         plt.subplot(1, 10, i)\n",
    "#         plt.imshow(vol[i,:,:])\n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "cpaths = glob.glob('/work/06850/sbansal6/maverick2/mriqc-shared/test_conformed/*/*')\n",
    "\n",
    "images = []\n",
    "nslices = 16\n",
    "\n",
    "for v in cpaths:\n",
    "    \n",
    "    \n",
    "    vol, _, _ = load_vol(v)\n",
    "    vol = np.array(vol)\n",
    "    vol = clip(vol, q=90)\n",
    "    vol = normalize(vol)\n",
    "    vol = standardize(vol)\n",
    "    \n",
    "    # get Coronal\n",
    "    vol = np.transpose(vol, (2, 0, 1))\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     for i in range(1, 31):\n",
    "#         plt.subplot(1, 31, i)\n",
    "#         plt.imshow(vol[i+24,:,:])\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    for i in range(1, nslices+1):\n",
    "        im = vol[i+64, :, :]\n",
    "        images.append(im)\n",
    "        \n",
    "print(len(images))\n",
    "\n",
    "images = np.array(images)*255\n",
    "\n",
    "total_width = 128*nslices\n",
    "total_height = 128*len(cpaths)\n",
    "    \n",
    "new_im = Image.new('RGB',(total_height, total_width))\n",
    "\n",
    "nrows = len(cpaths)\n",
    "ncols = nslices\n",
    "im_size = 128\n",
    "\n",
    "print(new_im)\n",
    "for im in range(len(images)):\n",
    "    imag = Image.fromarray(images[im])\n",
    "#     print(images[im].shape)\n",
    "    x, y = im_size*int(im/ncols), im_size*int(im%ncols)\n",
    "    new_im.paste(imag, (x,y))\n",
    "    if y % 128 == 0:\n",
    "        draw = ImageDraw.Draw(new_im)\n",
    "        text = str(labels[int(im % len(images)/nslices)])\n",
    "#         print(text)\n",
    "        draw.text((x,y), text)\n",
    "    \n",
    "\n",
    "new_im.save('mosaic/' + 'test_images_misclassified_axial.png')\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(new_im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "f = open(\"discovered.txt\", \"r\")\n",
    "discovered = f.read().splitlines()\n",
    "\n",
    "defaced = os.listdir('/work/01329/poldrack/data/mriqc-net/data/defaced')\n",
    "\n",
    "for ds in defaced:\n",
    "    for dis in discovered:\n",
    "        if dis in ds:\n",
    "            print(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for vol in data['volume'].values:\n",
    "    conf = data.loc[data['volume'] == vol, 'confidence'].item()\n",
    "    label = data.loc[data['volume'] == vol, 'label'].item()\n",
    "    \n",
    "    if vol in tvolumes:\n",
    "        if label == tvolumes[vol]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    else:\n",
    "        print(vol)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = glob.glob('/work/06850/sbansal6/maverick2/mriqc-shared/experiment_data_all/F15_csv/train/*')\n",
    "\n",
    "# combined_train_csv = pd.read_csv()\n",
    "average_train_accuracy = 0\n",
    "for csv in csv_paths:\n",
    "    accuracies = pd.read_csv(csv)[\"Value\"].values\n",
    "    average_train_accuracy += accuracies[-1]\n",
    "    \n",
    "average_train_accuracy = average_train_accuracy/15\n",
    "print(\"Average 15 fold training accuracy for combined model: \", average_train_accuracy)\n",
    "\n",
    "csv_paths = glob.glob('/work/06850/sbansal6/maverick2/mriqc-shared/experiment_data_all/F15_csv/validation/*')\n",
    "\n",
    "# combined_train_csv = pd.read_csv()\n",
    "average_valid_accuracy = 0\n",
    "for csv in csv_paths:\n",
    "    accuracies = pd.read_csv(csv)[\"Value\"].values\n",
    "    average_valid_accuracy += accuracies[-1]\n",
    "#     print(accuracies[-1])\n",
    "    \n",
    "average_valid_accuracy = average_valid_accuracy/15\n",
    "print(\"Average 15 fold validation accuracy for combined model: \", average_valid_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
